<!DOCTYPE html>
<!-- saved from url=(0057)https://en.wikipedia.org/wiki/Stochastic_gradient_descent -->
<html lang="en" dir="ltr" class="client-js ve-not-available"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="UTF-8">
<title>Stochastic gradient descent - Wikipedia, the free encyclopedia</title>
<script>document.documentElement.className = document.documentElement.className.replace( /(^|\s)client-nojs(\s|$)/, "$1client-js$2" );</script>
<script>window.RLQ = window.RLQ || []; window.RLQ.push( function () {
mw.config.set({"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":!1,"wgNamespaceNumber":0,"wgPageName":"Stochastic_gradient_descent","wgTitle":"Stochastic gradient descent","wgCurRevisionId":674349666,"wgRevisionId":674349666,"wgArticleId":1180641,"wgIsArticle":!0,"wgIsRedirect":!1,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["Articles with inconsistent citation formats","All articles with unsourced statements","Articles with unsourced statements from July 2015","Stochastic optimization","Computational statistics","M-estimators","Machine learning algorithms","Convex optimization"],"wgBreakFrames":!1,"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgMonthNamesShort":["","Jan","Feb","Mar","Apr","May","Jun",
"Jul","Aug","Sep","Oct","Nov","Dec"],"wgRelevantPageName":"Stochastic_gradient_descent","wgRelevantArticleId":1180641,"wgIsProbablyEditable":!0,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgMediaViewerOnClick":!0,"wgMediaViewerEnabledByDefault":!0,"wikilove-recipient":"","wikilove-anon":0,"wgWikiEditorEnabledModules":{"toolbar":!0,"dialogs":!0,"preview":!1,"publish":!1},"wgBetaFeaturesFeatures":[],"wgVisualEditor":{"pageLanguageCode":"en","pageLanguageDir":"ltr","usePageImages":!0,"usePageDescriptions":!0},"wgGatherShouldShowTutorial":!0,"wgGatherPageImageThumbnail":"//upload.wikimedia.org/wikipedia/en/thumb/f/f3/Stogra.png/100px-Stogra.png","wgULSAcceptLanguageList":[],"wgULSCurrentAutonym":"English","wgFlaggedRevsParams":{"tags":{"status":{"levels":1,"quality":2,"pristine":3}}},"wgStableRevisionId":null,"wgCategoryTreePageCategoryOptions":"{\"mode\":0,\"hideprefix\":20,\"showcount\":true,\"namespaces\":false}","wgNoticeProject":"wikipedia","wgWikibaseItemId":
"Q7617819","wgVisualEditorToolbarScrollOffset":0});mw.loader.implement("user.options",function($,jQuery){mw.user.options.set({"variant":"en"});});mw.loader.implement("user.tokens",function($,jQuery){mw.user.tokens.set({"editToken":"+\\","patrolToken":"+\\","watchToken":"+\\"});});mw.loader.load(["mediawiki.page.startup","mediawiki.legacy.wikibits","ext.centralauth.centralautologin","mmv.head","ext.gadget.WatchlistBase","ext.gadget.WatchlistGreenIndicators","ext.visualEditor.desktopArticleTarget.init","ext.uls.init","ext.uls.interface","ext.centralNotice.bannerController","skins.vector.js"]);
} );</script>
<link rel="stylesheet" href="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/load.php">
<link rel="stylesheet" href="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/load(1).php" media="print">
<style>
@-webkit-keyframes centralAuthPPersonalAnimation{0%{opacity:0;-webkit-transform:translateY(-20px)}100%{opacity:1;-webkit-transform:translateY(0)}}@-moz-keyframes centralAuthPPersonalAnimation{0%{opacity:0;-moz-transform:translateY(-20px)}100%{opacity:1;-moz-transform:translateY(0)}}@-o-keyframes centralAuthPPersonalAnimation{0%{opacity:0;-o-transform:translateY(-20px)}100%{opacity:1;-o-transform:translateY(0)}}@keyframes centralAuthPPersonalAnimation{0%{opacity:0;transform:translateY(-20px)}100%{opacity:1;transform:translateY(0)}}.centralAuthPPersonalAnimation{-webkit-animation-duration:1s;-moz-animation-duration:1s;-o-animation-duration:1s;animation-duration:1s;-webkit-animation-fill-mode:both;-moz-animation-fill-mode:both;-o-animation-fill-mode:both;animation-fill-mode:both;-webkit-animation-name:centralAuthPPersonalAnimation;-moz-animation-name:centralAuthPPersonalAnimation;-o-animation-name:centralAuthPPersonalAnimation;animation-name:centralAuthPPersonalAnimation}
.mw-changeslist-line-watched .mw-title{font-weight:bold} .mw-changeslist .mw-tag-marker,.mw-changeslist .mw-title{unicode-bidi:embed}
.ve-activated #toc,.ve-activated #siteNotice,.ve-activated .mw-indicators, .ve-active #bodyContent > :not(#siteSub):not(#contentSub):not(.ve-ui-mwTocWidget),.ve-activated #t-print,.ve-activated #t-permalink,.ve-activated #p-coll-print_export,.ve-activated #t-cite,.ve-activating .ve-ui-surface,.ve-deactivating .ve-ui-surface{display:none}.ve-activated #bodyContent,.ve-activated #firstHeading,.ve-activated #siteSub,.ve-activated #contentSub{opacity:0.6;pointer-events:none}.ve-activated #firstHeading{cursor:default} .ve-activated #content{position:relative}.ve-init-mw-desktopArticleTarget-loading-overlay{position:absolute;left:0;right:0;z-index:1;margin-top:-0.5em}.ve-init-mw-desktopArticleTarget-progress{border:1px solid #347bff;background:#fff;height:0.75em;border-radius:2px;overflow:hidden;margin:0 25%}.ve-init-mw-desktopArticleTarget-progress-bar{width:0;height:0.75em;background:#347bff} .mw-editsection{white-space:nowrap; unicode-bidi:-moz-isolate;unicode-bidi:-webkit-isolate;unicode-bidi:isolate}.mw-editsection-divider{color:#555}.ve-tabmessage-appendix{font-size:0.7em;vertical-align:top;line-height:1.43em;padding-left:0.5em; background-image:none !important;display:inline !important}
.uls-menu a{cursor:pointer}.uls-menu.callout .caret-before{border-top:20px solid transparent;border-right:20px solid #C9C9C9;border-bottom:20px solid transparent;display:inline-block;left:-21px;top:30px;position:absolute}.uls-menu.callout .caret-after{border-top:20px solid transparent;border-right:20px solid #FCFCFC;border-bottom:20px solid transparent;display:inline-block;left:-20px;top:30px;position:absolute}.uls-ui-languages button{width:23%;text-overflow:ellipsis;margin-right:4%}button.uls-more-languages{width:auto}.settings-title{font-size:11pt}.settings-text{color:#555555;font-size:9pt}div.display-settings-block:hover .settings-text{color:#252525}
.tipsy{padding:5px;position:absolute;z-index:100000;cursor:default}.tipsy-inner{padding:5px 8px 4px 8px; background-color:#ffffff;border:solid 1px #a7d7f9;color:black;max-width:15em;border-radius:4px; }.tipsy-arrow{position:absolute;background:url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAALAgMAAADUwp+1AAAACVBMVEX5+fmn1/n///9s6BFKAAAAAXRSTlMAQObYZgAAACpJREFUCB1jZBD4wMiQMoeRcUU4I9uSaYxSE54xZjn8AtMgPkgcJA9UBwAeDw1Qrb3pVAAAAABJRU5ErkJggg==) no-repeat top left;background:url(https://en.wikipedia.org/static/1.26wmf19/resources/src/jquery.tipsy/images/tipsy.png?6c317) no-repeat top left!ie;width:11px;height:6px} .tipsy-n .tipsy-arrow{top:0px;left:50%;margin-left:-5px} .tipsy-nw .tipsy-arrow{top:1px;left:10px} .tipsy-ne .tipsy-arrow{top:1px;right:10px} .tipsy-s .tipsy-arrow{bottom:0px;left:50%;margin-left:-5px;background-position:bottom left} .tipsy-sw .tipsy-arrow{bottom:0px;left:10px;background-position:bottom left} .tipsy-se .tipsy-arrow{bottom:0px;right:10px;background-position:bottom left} .tipsy-e .tipsy-arrow{top:50%;margin-top:-5px;right:1px;width:5px;height:11px;background-position:top right} .tipsy-w .tipsy-arrow{top:50%;margin-top:-5px;left:0px;width:6px;height:11px} .tipsy{font-size:0.8em}
@media print{#centralNotice{display:none}}
.cite-accessibility-label{position:absolute !important; top:-99999px;clip:rect(1px 1px 1px 1px); clip:rect(1px,1px,1px,1px);padding:0 !important;border:0 !important;height:1px !important;width:1px !important;overflow:hidden}
.postedit-container{margin:0 auto;position:fixed;top:0;height:0;left:50%;z-index:1000;font-size:13px}.postedit-container:hover{cursor:pointer}.postedit{position:relative;top:0.6em;left:-50%;padding:.6em 3.6em .6em 1.1em;line-height:1.5625em;color:#626465;background-color:#f4f4f4;border:1px solid #dcd9d9;text-shadow:0 0.0625em 0 rgba(255,255,255,0.5);border-radius:5px;box-shadow:0 2px 5px 0 #ccc;-webkit-transition:all 0.25s ease-in-out;-moz-transition:all 0.25s ease-in-out;-ms-transition:all 0.25s ease-in-out;-o-transition:all 0.25s ease-in-out;transition:all 0.25s ease-in-out}.skin-monobook .postedit{top:6em !important}.postedit-faded{opacity:0}.postedit-icon{padding-left:41px;  line-height:25px;background-repeat:no-repeat;background-position:8px 50%}.postedit-icon-checkmark{background-image:url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAMAAAAoLQ9TAAABblBMVEUAAAD///////9PfTf///80aRdTgjn///9Feij///////////9Rfzf///////////9PfjZRgDh1o1xOfTb///////+bwYqLtnj///////9PfTa82K////9WhT6YxIL///9QgDdTgzr////////j7uDl7eLq8efi693k7OH///////9UhjuBr2rp9uRUhjr///9YljVKgir///9WiTlYjT3////9/v57vFlbkT5PjC9dlD/5/fhuq09stUTs9uhxuElctCpfnT1huDFloEZloUZmpENmvDZpvDxpvTxqvjxrvT5rvT9rwTxsqktswD5uwkBvuUdxw0NztFBztU9ztVBzwkp0tlJ1xkd2t1R3uVR4w1F4xk54x014yE15uVZ5v1R5xVB6v1R7yFJ8wVh9xVl9yFR9yVd9ylN+xVh+yFd/x1l/yFeAylmEx1+Ny2uY0Hqe04Wj1Ymv3Ze33qLD47TJ5L3O6cPU7Mrq9eb2+/Q4j37OAAAAQHRSTlMAAQIEBAUFBQwPFB4fJCUoKiosQEhJS01RUlZZXmdydXaChYuSlJSWmJmoq6uur8LExcvM19fg5ejt8fX2+Pr7SljgewAAAKpJREFUGBkFwQNCAwAAAMDLtl3LtrG4rWXbtvX77gAgZ6grFwC0bhwNVgKgdPZx8b0dgLi+s7Wn0VoAqpfOI9+BNADZI7fLrz2pSEwGHZuH+78lSK8ZLkLezF3ooyUG3VPXq2USei9WngeyoG195yBYWDF3E/2pAhl1e9Gr8bGT+bfOFCC2fnvh4X7rcqIAQNNu+HT6sxkAjceTL/2ZAIhv+PorBwBJxfkA//dFHSCBy/UTAAAAAElFTkSuQmCC);background-image:url(https://en.wikipedia.org/static/1.26wmf21/resources/src/mediawiki.action/images/green-checkmark.png?9048a)!ie;background-position:left}.postedit-close{position:absolute;padding:0 .8em;right:0;top:0;font-size:1.25em;font-weight:bold;line-height:2.3em;color:black;text-shadow:0 0.0625em 0 white;text-decoration:none;opacity:0.2;filter:alpha(opacity=20)}.postedit-close:hover{color:black;text-decoration:none;opacity:0.4;filter:alpha(opacity=40)}
dfn{font-style:inherit} q{quotes:'"' '"' "'" "'"} blockquote{overflow:hidden;margin:1em 0;padding:0 40px} strong.selflink{font-weight:700} .mw-body sub,.mw-body sup,span.reference {font-size:80%} #interwiki-completelist{font-weight:bold}body.page-Main_Page #ca-delete{display:none !important}body.page-Main_Page #mp-topbanner{clear:both} #toolbar{height:22px;margin-bottom:6px} #editpage-specialchars{display:none} body.action-info :target{background:#DEF} ol.references,div.reflist,div.refbegin{font-size:90%; margin-bottom:0.5em}div.refbegin-100{font-size:100%; }div.reflist ol.references{font-size:100%; list-style-type:inherit; } span.citation:target{background-color:#DEF} sup.reference{font-weight:normal;font-style:normal} span.brokenref{display:none} .citation{word-wrap:break-word} @media screen,handheld{.citation .printonly{display:none}} div.columns{margin-top:0.3em}div.columns dl,div.columns ol,div.columns ul{margin-top:0} .nocolbreak,div.columns li,div.columns dd dd{-webkit-column-break-inside:avoid;page-break-inside:avoid;break-inside:avoid-column} .flowlist ul{overflow-x:hidden;margin-left:0;padding-left:1.6em}.flowlist ol{overflow-x:hidden;margin-left:0;padding-left:3.2em}.flowlist dl{overflow-x:hidden} .hlist dl,.hlist ol,.hlist ul{margin:0;padding:0} .hlist dd,.hlist dt,.hlist li{margin:0;display:inline} .hlist.inline,.hlist.inline dl,.hlist.inline ol,.hlist.inline ul,.hlist dl dl,.hlist dl ol,.hlist dl ul,.hlist ol dl,.hlist ol ol,.hlist ol ul,.hlist ul dl,.hlist ul ol,.hlist ul ul{display:inline} .hlist dt:after{content:":"}.hlist dd:after,.hlist li:after{content:" Â· ";font-weight:bold}.hlist dd:last-child:after,.hlist dt:last-child:after,.hlist li:last-child:after{content:none} .hlist dd.hlist-last-child:after,.hlist dt.hlist-last-child:after,.hlist li.hlist-last-child:after{content:none} .hlist dd dd:first-child:before,.hlist dd dt:first-child:before,.hlist dd li:first-child:before,.hlist dt dd:first-child:before,.hlist dt dt:first-child:before,.hlist dt li:first-child:before,.hlist li dd:first-child:before,.hlist li dt:first-child:before,.hlist li li:first-child:before{content:" (";font-weight:normal}.hlist dd dd:last-child:after,.hlist dd dt:last-child:after,.hlist dd li:last-child:after,.hlist dt dd:last-child:after,.hlist dt dt:last-child:after,.hlist dt li:last-child:after,.hlist li dd:last-child:after,.hlist li dt:last-child:after,.hlist li li:last-child:after{content:") ";font-weight:normal} .hlist dd dd.hlist-last-child:after,.hlist dd dt.hlist-last-child:after,.hlist dd li.hlist-last-child:after,.hlist dt dd.hlist-last-child:after,.hlist dt dt.hlist-last-child:after,.hlist dt li.hlist-last-child:after,.hlist li dd.hlist-last-child:after,.hlist li dt.hlist-last-child:after,.hlist li li.hlist-last-child:after{content:") ";font-weight:normal} .hlist ol{counter-reset:listitem}.hlist ol > li{counter-increment:listitem}.hlist ol > li:before{content:" " counter(listitem) " ";white-space:nowrap}.hlist dd ol > li:first-child:before,.hlist dt ol > li:first-child:before,.hlist li ol > li:first-child:before{content:" (" counter(listitem) " "} .plainlist ol,.plainlist ul{line-height:inherit;list-style:none none;margin:0}.plainlist ol li,.plainlist ul li{margin-bottom:0} .navbox{ border:1px solid #aaa;width:100%;margin:auto;clear:both;font-size:88%;text-align:center;padding:1px}.navbox-inner,.navbox-subgroup{width:100%}.navbox-group,.navbox-title,.navbox-abovebelow{padding:0.25em 1em; line-height:1.5em;text-align:center}th.navbox-group{ white-space:nowrap; text-align:right}.navbox,.navbox-subgroup{background:#fdfdfd; }.navbox-list{line-height:1.5em;border-color:#fdfdfd; }.navbox th,.navbox-title{background:#ccccff; }.navbox-abovebelow,th.navbox-group,.navbox-subgroup .navbox-title{background:#ddddff; }.navbox-subgroup .navbox-group,.navbox-subgroup .navbox-abovebelow{background:#e6e6ff; }.navbox-even{background:#f7f7f7; }.navbox-odd{background:transparent; }table.navbox{margin-top:1em; }table.navbox table.navbox{margin-top:0; }table.navbox + table.navbox{margin-top:-1px; }.navbox .hlist td dl,.navbox .hlist td ol,.navbox .hlist td ul,.navbox td.hlist dl,.navbox td.hlist ol,.navbox td.hlist ul{padding:0.125em 0; } .navbar{display:inline;font-size:88%;font-weight:normal}.navbar ul{display:inline;white-space:nowrap}.mw-body-content .navbar ul{line-height:inherit}.navbar li{word-spacing:-0.125em}.navbar.mini li span{font-variant:small-caps} .infobox .navbar{font-size:100%}.navbox .navbar{display:block;font-size:100%}.navbox-title .navbar{ float:left; text-align:left; margin-right:0.5em;width:6em} .collapseButton{ float:right;font-weight:normal; margin-left:0.5em; text-align:right;width:auto} .navbox .collapseButton{width:6em} .mw-collapsible-toggle{font-weight:normal; text-align:right}.navbox .mw-collapsible-toggle{width:6em} .infobox{border:1px solid #aaa;border-spacing:3px;background-color:#f9f9f9;color:black; margin:0.5em 0 0.5em 1em;padding:0.2em; float:right; clear:right;font-size:88%;line-height:1.5em}.infobox caption{font-size:125%;font-weight:bold;padding:0.2em}.infobox td,.infobox th{vertical-align:top; text-align:left}.infobox.bordered{border-collapse:collapse}.infobox.bordered td,.infobox.bordered th{border:1px solid #aaa}.infobox.bordered .borderless td,.infobox.bordered .borderless th{border:0}.infobox.sisterproject{width:20em;font-size:90%}.infobox.standard-talk{border:1px solid #c0c090;background-color:#f8eaba}.infobox.standard-talk.bordered td,.infobox.standard-talk.bordered th{border:1px solid #c0c090} .infobox.bordered .mergedtoprow td,.infobox.bordered .mergedtoprow th{border:0;border-top:1px solid #aaa; border-right:1px solid #aaa}.infobox.bordered .mergedrow td,.infobox.bordered .mergedrow th{border:0; border-right:1px solid #aaa} .infobox.geography{border-collapse:collapse;line-height:1.2em;font-size:90%}.infobox.geography td,.infobox.geography th{border-top:1px solid #aaa;padding:0.4em 0.6em 0.4em 0.6em}.infobox.geography .mergedtoprow td,.infobox.geography .mergedtoprow th{border-top:1px solid #aaa;padding:0.4em 0.6em 0.2em 0.6em}.infobox.geography .mergedrow td,.infobox.geography .mergedrow th{border:0;padding:0 0.6em 0.2em 0.6em}.infobox.geography .mergedbottomrow td,.infobox.geography .mergedbottomrow th{border-top:0;border-bottom:1px solid #aaa;padding:0 0.6em 0.4em 0.6em}.infobox.geography .maptable td,.infobox.geography .maptable th{border:0;padding:0} .wikitable.plainrowheaders th[scope=row]{font-weight:normal; text-align:left} .wikitable td ul,.wikitable td ol,.wikitable td dl{ text-align:left} .toc.hlist ul,#toc.hlist ul,.wikitable.hlist td ul,.wikitable.hlist td ol,.wikitable.hlist td dl{text-align:inherit} div.listenlist{background:url(//upload.wikimedia.org/wikipedia/commons/4/47/Sound-icon.svg) no-repeat scroll 0 0 transparent;background-size:30px;padding-left:40px} table.mw-hiero-table td{vertical-align:middle} div.medialist{min-height:50px;margin:1em; background-position:top left;background-repeat:no-repeat}div.medialist ul{list-style-type:none;list-style-image:none;margin:0}div.medialist ul li{padding-bottom:0.5em}div.medialist ul li li{font-size:91%;padding-bottom:0} div#content a[href$=".pdf"].external,div#content a[href*=".pdf?"].external,div#content a[href*=".pdf#"].external,div#content a[href$=".PDF"].external,div#content a[href*=".PDF?"].external,div#content a[href*=".PDF#"].external,div#mw_content a[href$=".pdf"].external,div#mw_content a[href*=".pdf?"].external,div#mw_content a[href*=".pdf#"].external,div#mw_content a[href$=".PDF"].external,div#mw_content a[href*=".PDF?"].external,div#mw_content a[href*=".PDF#"].external{background:url(//upload.wikimedia.org/wikipedia/commons/2/23/Icons-mini-file_acrobat.gif) no-repeat right; padding-right:18px} div#content span.PDFlink a,div#mw_content span.PDFlink a{background:url(//upload.wikimedia.org/wikipedia/commons/2/23/Icons-mini-file_acrobat.gif) no-repeat right; padding-right:18px} div.columns-2 div.column{ float:left;width:50%;min-width:300px}div.columns-3 div.column{ float:left;width:33.3%;min-width:200px}div.columns-4 div.column{ float:left;width:25%;min-width:150px}div.columns-5 div.column{ float:left;width:20%;min-width:120px} .messagebox{border:1px solid #aaa;background-color:#f9f9f9;width:80%;margin:0 auto 1em auto;padding:.2em}.messagebox.merge{border:1px solid #c0b8cc;background-color:#f0e5ff;text-align:center}.messagebox.cleanup{border:1px solid #9f9fff;background-color:#efefff;text-align:center}.messagebox.standard-talk{border:1px solid #c0c090;background-color:#f8eaba;margin:4px auto} .mbox-inside .standard-talk,.messagebox.nested-talk{border:1px solid #c0c090;background-color:#f8eaba;width:100%;margin:2px 0;padding:2px}.messagebox.small{width:238px;font-size:85%; float:right;clear:both; margin:0 0 1em 1em;line-height:1.25em}.messagebox.small-talk{width:238px;font-size:85%; float:right;clear:both; margin:0 0 1em 1em;line-height:1.25em;background:#F8EABA} th.mbox-text,td.mbox-text{ border:none; padding:0.25em 0.9em; width:100%; }td.mbox-image{ border:none; padding:2px 0 2px 0.9em; text-align:center}td.mbox-imageright{ border:none; padding:2px 0.9em 2px 0; text-align:center}td.mbox-empty-cell{ border:none;padding:0;width:1px} table.ambox{margin:0 10%; border:1px solid #aaa; border-left:10px solid #1e90ff; background:#fbfbfb}table.ambox + table.ambox{ margin-top:-1px}.ambox th.mbox-text,.ambox td.mbox-text{ padding:0.25em 0.5em; }.ambox td.mbox-image{  padding:2px 0 2px 0.5em; }.ambox td.mbox-imageright{  padding:2px 0.5em 2px 0; }table.ambox-notice{ border-left:10px solid #1e90ff; }table.ambox-speedy{ border-left:10px solid #b22222; background:#fee; }table.ambox-delete{ border-left:10px solid #b22222; }table.ambox-content{ border-left:10px solid #f28500; }table.ambox-style{ border-left:10px solid #f4c430; }table.ambox-move{ border-left:10px solid #9932cc; }table.ambox-protection{ border-left:10px solid #bba; } table.imbox{margin:4px 10%;border-collapse:collapse;border:3px solid #1e90ff; background:#fbfbfb}.imbox .mbox-text .imbox{ margin:0 -0.5em; display:block; }.mbox-inside .imbox{ margin:4px}table.imbox-notice{border:3px solid #1e90ff; }table.imbox-speedy{border:3px solid #b22222; background:#fee; }table.imbox-delete{border:3px solid #b22222; }table.imbox-content{border:3px solid #f28500; }table.imbox-style{border:3px solid #f4c430; }table.imbox-move{border:3px solid #9932cc; }table.imbox-protection{border:3px solid #bba; }table.imbox-license{border:3px solid #88a; background:#f7f8ff; }table.imbox-featured{border:3px solid #cba135; } table.cmbox{margin:3px 10%;border-collapse:collapse;border:1px solid #aaa;background:#DFE8FF; }table.cmbox-notice{background:#D8E8FF; }table.cmbox-speedy{margin-top:4px;margin-bottom:4px;border:4px solid #b22222; background:#FFDBDB; }table.cmbox-delete{background:#FFDBDB; }table.cmbox-content{background:#FFE7CE; }table.cmbox-style{background:#FFF9DB; }table.cmbox-move{background:#E4D8FF; }table.cmbox-protection{background:#EFEFE1; } table.ombox{margin:4px 10%;border-collapse:collapse;border:1px solid #aaa; background:#f9f9f9}table.ombox-notice{border:1px solid #aaa; }table.ombox-speedy{border:2px solid #b22222; background:#fee; }table.ombox-delete{border:2px solid #b22222; }table.ombox-content{border:1px solid #f28500; }table.ombox-style{border:1px solid #f4c430; }table.ombox-move{border:1px solid #9932cc; }table.ombox-protection{border:2px solid #bba; } table.tmbox{margin:4px 10%;border-collapse:collapse;border:1px solid #c0c090; background:#f8eaba}.mediawiki .mbox-inside .tmbox{ margin:2px 0; width:100%; }.mbox-inside .tmbox.mbox-small{ line-height:1.5em; font-size:100%; }table.tmbox-speedy{border:2px solid #b22222; background:#fee; }table.tmbox-delete{border:2px solid #b22222; }table.tmbox-content{border:2px solid #f28500; }table.tmbox-style{border:2px solid #f4c430; }table.tmbox-move{border:2px solid #9932cc; }table.tmbox-protection,table.tmbox-notice{border:1px solid #c0c090; } table.dmbox{clear:both;margin:0.9em 1em;border-top:1px solid #ccc;border-bottom:1px solid #ccc;background:transparent} table.fmbox{clear:both;margin:0.2em 0;width:100%;border:1px solid #aaa;background:#f9f9f9; }table.fmbox-system{background:#f9f9f9}table.fmbox-warning{border:1px solid #bb7070; background:#ffdbdb; }table.fmbox-editnotice{background:transparent} div.mw-warning-with-logexcerpt,div.mw-lag-warn-high,div.mw-cascadeprotectedwarning,div#mw-protect-cascadeon,div.titleblacklist-warning,div.locked-warning{clear:both;margin:0.2em 0;border:1px solid #bb7070;background:#ffdbdb;padding:0.25em 0.9em} div.mw-lag-warn-normal,div.fmbox-system{clear:both;margin:0.2em 0;border:1px solid #aaa;background:#f9f9f9;padding:0.25em 0.9em} body.mediawiki table.mbox-small{  clear:right; float:right; margin:4px 0 4px 1em;width:238px;font-size:88%;line-height:1.25em}body.mediawiki table.mbox-small-left{  margin:4px 1em 4px 0;width:238px;border-collapse:collapse;font-size:88%;line-height:1.25em}  .compact-ambox table .mbox-image,.compact-ambox table .mbox-imageright,.compact-ambox table .mbox-empty-cell{display:none} .compact-ambox table.ambox{border:none;border-collapse:collapse;background:transparent;margin:0 0 0 1.6em !important;padding:0 !important;width:auto;display:block}body.mediawiki .compact-ambox table.mbox-small-left{font-size:100%;width:auto;margin:0} .compact-ambox table .mbox-text{padding:0 !important;margin:0 !important}.compact-ambox table .mbox-text-span{display:list-item;line-height:1.5em;list-style-type:square;list-style-image:url(//en.wikipedia.org/w/skins/MonoBook/bullet.gif)}.skin-vector .compact-ambox table .mbox-text-span{list-style-type:disc;list-style-image:url(//en.wikipedia.org/w/skins/Vector/images/bullet-icon.png) } .compact-ambox .hide-when-compact{display:none} div.noarticletext{border:none;background:transparent;padding:0} .visualhide{position:absolute;left:-10000px;top:auto;width:1px;height:1px;overflow:hidden} #wpSave{font-weight:bold} .hiddenStructure{display:inline !important;color:#f00;background-color:#0f0} .check-icon a.new{display:none;speak:none} .nounderlines a,.IPA a:link,.IPA a:visited{text-decoration:none !important} div.NavFrame{margin:0;padding:4px;border:1px solid #aaa;text-align:center;border-collapse:collapse;font-size:95%}div.NavFrame + div.NavFrame{border-top-style:none;border-top-style:hidden}div.NavPic{background-color:#fff;margin:0;padding:2px; float:left}div.NavFrame div.NavHead{line-height:1.6em;font-weight:bold;background-color:#ccf;position:relative}div.NavFrame p,div.NavFrame div.NavContent,div.NavFrame div.NavContent p{font-size:100%}div.NavEnd{margin:0;padding:0;line-height:1px;clear:both}a.NavToggle{position:absolute;top:0; right:3px;font-weight:normal;font-size:90%} .hatnote{font-style:italic}.hatnote i{font-style:normal}div.hatnote{ padding-left:1.6em;margin-bottom:0.5em}div.hatnote + div.hatnote{margin-top:-0.5em} .listify td{display:list-item}.listify tr{display:block}.listify table{display:block} .geo-default,.geo-dms,.geo-dec{display:inline}.geo-nondefault,.geo-multi-punct{display:none}.longitude,.latitude{white-space:nowrap} .nonumtoc .tocnumber{display:none}.nonumtoc #toc ul,.nonumtoc .toc ul{line-height:1.5em;list-style:none none;margin:.3em 0 0;padding:0}.hlist.nonumtoc #toc ul ul,.hlist.nonumtoc .toc ul ul{ margin:0} .toclimit-2 .toclevel-1 ul,.toclimit-3 .toclevel-2 ul,.toclimit-4 .toclevel-3 ul,.toclimit-5 .toclevel-4 ul,.toclimit-6 .toclevel-5 ul,.toclimit-7 .toclevel-6 ul{display:none} blockquote.templatequote div.templatequotecite{line-height:1.5em; text-align:left; padding-left:1.6em;margin-top:0} div.user-block{padding:5px;margin-bottom:0.5em;border:1px solid #A9A9A9;background-color:#FFEFD5} .nowrap,.nowraplinks a,.nowraplinks .selflink,sup.reference a{white-space:nowrap} .wrap,.wraplinks a{white-space:normal} .template-documentation{clear:both;margin:1em 0 0 0;border:1px solid #aaa;background-color:#ecfcf4;padding:1em} .imagemap-inline div{display:inline} #wpUploadDescription{height:13em} .thumbinner{min-width:100px} div.thumb .thumbimage{background-color:#fff} div#content .gallerybox div.thumb{ background-color:#F9F9F9} .gallerybox .thumb img{background:#fff url(//upload.wikimedia.org/wikipedia/commons/5/5d/Checker-16x16.png) repeat} .ns-0 .gallerybox .thumb img,.ns-2 .gallerybox .thumb img,.ns-100 .gallerybox .thumb img,.nochecker .gallerybox .thumb img{background:#fff} #mw-subcategories,#mw-pages,#mw-category-media,#filehistory,#wikiPreview,#wikiDiff{clear:both}body.rtl #mw-articlefeedbackv5,body.rtl #mw-articlefeedback{display:block; margin-bottom:1em; clear:right;  float:right; } .wpb .wpb-header{display:none}.wpbs-inner .wpb .wpb-header{display:block} .wpbs-inner .wpb .wpb-header{display:table-row} .wpbs-inner .wpb-outside{display:none}  .mw-tag-markers{font-style:italic;font-size:90%} .sysop-show,.accountcreator-show,.templateeditor-show,.autoconfirmed-show{display:none} .ve-ui-mwNoticesPopupTool-item .editnotice-redlink,.mw-ve-editNotice .editnotice-redlink{display:none !important} ul.permissions-errors > li{list-style:none none}ul.permissions-errors{margin:0} body.page-Special_UserLogin .mw-label label,body.page-Special_UserLogin_signup .mw-label label{white-space:nowrap} .transborder{border:solid transparent}* html .transborder{ border:solid #000001;filter:chroma(color=#000001)} .times-serif,span.texhtml{font-family:"Nimbus Roman No9 L","Times New Roman",Times,serif;font-size:118%;line-height:1}span.texhtml{white-space:nowrap}span.texhtml span.texhtml{font-size:100%} .digits,.texhtml{-moz-font-feature-settings:"lnum","tnum","kern" 0;-webkit-font-feature-settings:"lnum","tnum","kern" 0;font-feature-settings:"lnum","tnum","kern" 0;font-variant-numeric:lining-nums tabular-nums;font-kerning:none} table#mw-prefixindex-list-table,table#mw-prefixindex-nav-table{width:98%} .portal-column-left{float:left;width:50%}.portal-column-right{float:right;width:49%}.portal-column-left-wide{float:left;width:60%}.portal-column-right-narrow{float:right;width:39%}.portal-column-left-extra-wide{float:left;width:70%}.portal-column-right-extra-narrow{float:right;width:29%}@media only screen and (max-width:800px){ .portal-column-left,.portal-column-right,.portal-column-left-wide,.portal-column-right-narrow,.portal-column-left-extra-wide,.portal-column-right-extra-narrow{float:inherit;width:inherit}} #bodyContent .letterhead{background-image:url(//upload.wikimedia.org/wikipedia/commons/e/e0/Tan-page-corner.png);background-repeat:no-repeat;padding:2em;background-color:#faf9f2} .treeview ul{padding:0;margin:0}.treeview li{padding:0;margin:0;list-style-type:none;list-style-image:none;zoom:1;}.treeview li li{background:url(//upload.wikimedia.org/wikipedia/commons/f/f2/Treeview-grey-line.png) no-repeat 0 -2981px; padding-left:20px;text-indent:0.3em}.treeview li li.lastline{background-position:0 -5971px }.treeview li.emptyline > ul{ margin-left:-1px}.treeview li.emptyline > ul > li:first-child{background-position:0 9px } td .sortkey,th .sortkey{display:none;speak:none} .inputbox-hidecheckboxes form .inputbox-element{display:none !important} .k-player .k-attribution{visibility:hidden} .PopUpMediaTransform a .play-btn-large{margin:0;top:auto;right:auto;bottom:0;left:0} .mw-ve-editNotice .mbox-image{display:none} #pagehistory input[type="checkbox"],.mw-history-revisionactions,#mw-log-deleterevision-submit input[type="checkbox"],.editchangetags-log-submit{display:none}
.page-Main_Page #deleteconfirm,.page-Main_Page #t-cite,.page-Main_Page #footer-info-lastmod,.action-view.page-Main_Page #siteSub,.action-view.page-Main_Page #contentSub,.action-view.page-Main_Page .firstHeading{display:none !important} #coordinates{position:absolute;top:0;right:0;float:right;margin:0;padding:0;line-height:1.5em;text-align:right;text-indent:0;font-size:85%;text-transform:none;white-space:nowrap} div.flaggedrevs_short{position:absolute;top:-3em;right:100px;z-index:1} div.vectorMenu div{z-index:2} #siteSub{display:block;font-size:92%} .mw-body .mw-indicators{padding-top:0.4em} div#simpleSearch{width:20vw;min-width:5em;max-width:20em}
@media print {
	.ns-0 .ambox,.ns-0 .navbox,.ns-0 .vertical-navbox,.ns-0 .infobox.sisterproject,.ns-0 .dablink,.ns-0 .metadata,.editlink,.navbar,a.NavToggle,span.collapseButton,span.mw-collapsible-toggle,th .sortkey,td .sortkey{display:none !important} #content cite a.external.text:after,.nourlexpansion a.external.text:after,.nourlexpansion a.external.autonumber:after{display:none !important} table.collapsible tr,div.NavPic,div.NavContent{display:block !important}table.collapsible tr{display:table-row !important} #firstHeading{margin:0} #content a.external.text:after,#content a.external.autonumber:after{word-wrap:break-word}}
.mw-collapsible-toggle{float:right;-moz-user-select:none;-webkit-user-select:none;-ms-user-select:none;user-select:none}  .mw-content-ltr .mw-collapsible-toggle,.mw-content-rtl .mw-content-ltr .mw-collapsible-toggle{float:right} .mw-content-rtl .mw-collapsible-toggle,.mw-content-ltr .mw-content-rtl .mw-collapsible-toggle{float:left}.mw-customtoggle,.mw-collapsible-toggle{cursor:pointer} caption .mw-collapsible-toggle,.mw-content-ltr caption .mw-collapsible-toggle,.mw-content-rtl caption .mw-collapsible-toggle,.mw-content-rtl .mw-content-ltr caption .mw-collapsible-toggle,.mw-content-ltr .mw-content-rtl caption .mw-collapsible-toggle{float:none} li .mw-collapsible-toggle,.mw-content-ltr li .mw-collapsible-toggle,.mw-content-rtl li .mw-collapsible-toggle,.mw-content-rtl .mw-content-ltr li .mw-collapsible-toggle,.mw-content-ltr .mw-content-rtl li .mw-collapsible-toggle{float:none} .mw-collapsible-toggle-li{list-style:none}
.suggestions{overflow:hidden;position:absolute;top:0;left:0;width:0;border:none;z-index:1099;padding:0;margin:-1px 0 0 0}.suggestions-special{position:relative;background-color:white;cursor:pointer;border:solid 1px #aaaaaa;padding:0;margin:0;margin-top:-2px;display:none;padding:0.25em 0.25em;line-height:1.25em}.suggestions-results{background-color:white;cursor:pointer;border:solid 1px #aaaaaa;padding:0;margin:0}.suggestions-result{color:black;margin:0;line-height:1.5em;padding:0.01em 0.25em;text-align:left; overflow:hidden;-o-text-overflow:ellipsis; text-overflow:ellipsis;white-space:nowrap}.suggestions-result-current{background-color:#4C59A6;color:white}.suggestions-special .special-label{color:gray;text-align:left}.suggestions-special .special-query{color:black;font-style:italic;text-align:left}.suggestions-special .special-hover{background-color:silver}.suggestions-result-current .special-label,.suggestions-result-current .special-query{color:white}.highlight{font-weight:bold}
.mw-ui-button{font-family:inherit;font-size:1em;display:inline-block;padding:.5em 1em;margin:0;-webkit-box-sizing:border-box;-moz-box-sizing:border-box;box-sizing:border-box;-webkit-appearance:none;*display:inline;zoom:1;background:#FFF;color:#555;border:1px solid #CCC;border-radius:2px;min-width:4em;vertical-align:middle;text-align:center;font-weight:bold;cursor:pointer;-webkit-transition:background .1s ease-in-out,color .1s ease-in-out,box-shadow .1s ease-in-out;-moz-transition:background .1s ease-in-out,color .1s ease-in-out,box-shadow .1s ease-in-out;-o-transition:background .1s ease-in-out,color .1s ease-in-out,box-shadow .1s ease-in-out;transition:background .1s ease-in-out,color .1s ease-in-out,box-shadow .1s ease-in-out}.mw-ui-button:hover{background-color:#CCC}.mw-ui-button:focus{border-color:#fff;box-shadow:0 0 0 1px #CCC;outline:none}.mw-ui-button:focus::-moz-focus-inner{border-color:transparent}.mw-ui-button:active,.mw-ui-button.mw-ui-checked{background:#777;box-shadow:none}.mw-ui-button:hover,.mw-ui-button:active,.mw-ui-button:visited{color:#555}.mw-ui-button:focus{background-color:#CCC}.mw-ui-button:disabled{color:#CCC}.mw-ui-button:disabled:hover,.mw-ui-button:disabled:active{background:#FFF;box-shadow:none}.mw-ui-button:disabled{text-shadow:none;cursor:default}.mw-ui-button.mw-ui-big{font-size:1.3em}.mw-ui-button.mw-ui-block{display:block;width:100%}.mw-ui-button.mw-ui-progressive,.mw-ui-button.mw-ui-primary{background:#347bff;color:#fff;border:1px solid #347bff;text-shadow:0 1px rgba(0,0,0,0.1)}.mw-ui-button.mw-ui-progressive:hover,.mw-ui-button.mw-ui-primary:hover{background-color:#2962CC}.mw-ui-button.mw-ui-progressive:focus,.mw-ui-button.mw-ui-primary:focus{border-color:#fff;box-shadow:0 0 0 1px #2962CC;outline:none}.mw-ui-button.mw-ui-progressive:focus::-moz-focus-inner,.mw-ui-button.mw-ui-primary:focus::-moz-focus-inner{border-color:transparent}.mw-ui-button.mw-ui-progressive:active,.mw-ui-button.mw-ui-progressive.mw-ui-checked,.mw-ui-button.mw-ui-primary:active,.mw-ui-button.mw-ui-primary.mw-ui-checked{background:#2962CC;box-shadow:none}.mw-ui-button.mw-ui-progressive:disabled,.mw-ui-button.mw-ui-primary:disabled{background:#DDD;border-color:#DDD}.mw-ui-button.mw-ui-progressive:disabled:hover,.mw-ui-button.mw-ui-progressive:disabled:active,.mw-ui-button.mw-ui-progressive:disabled.mw-ui-checked,.mw-ui-button.mw-ui-primary:disabled:hover,.mw-ui-button.mw-ui-primary:disabled:active,.mw-ui-button.mw-ui-primary:disabled.mw-ui-checked{box-shadow:none}.mw-ui-button.mw-ui-progressive.mw-ui-quiet,.mw-ui-button.mw-ui-primary.mw-ui-quiet{color:#555}.mw-ui-button.mw-ui-progressive.mw-ui-quiet:hover,.mw-ui-button.mw-ui-progressive.mw-ui-quiet:focus,.mw-ui-button.mw-ui-primary.mw-ui-quiet:hover,.mw-ui-button.mw-ui-primary.mw-ui-quiet:focus{background:transparent;color:#347bff}.mw-ui-button.mw-ui-progressive.mw-ui-quiet:active,.mw-ui-button.mw-ui-progressive.mw-ui-quiet.mw-ui-checked,.mw-ui-button.mw-ui-primary.mw-ui-quiet:active,.mw-ui-button.mw-ui-primary.mw-ui-quiet.mw-ui-checked{color:#2962CC}.mw-ui-button.mw-ui-progressive.mw-ui-quiet:disabled,.mw-ui-button.mw-ui-primary.mw-ui-quiet:disabled{color:#CCC}.mw-ui-button.mw-ui-constructive{background:#00af89;color:#fff;border:1px solid #00af89;text-shadow:0 1px rgba(0,0,0,0.1)}.mw-ui-button.mw-ui-constructive:hover{background-color:#008C6D}.mw-ui-button.mw-ui-constructive:focus{border-color:#fff;box-shadow:0 0 0 1px #008C6D;outline:none}.mw-ui-button.mw-ui-constructive:focus::-moz-focus-inner{border-color:transparent}.mw-ui-button.mw-ui-constructive:active,.mw-ui-button.mw-ui-constructive.mw-ui-checked{background:#008C6D;box-shadow:none}.mw-ui-button.mw-ui-constructive:disabled{background:#DDD;border-color:#DDD}.mw-ui-button.mw-ui-constructive:disabled:hover,.mw-ui-button.mw-ui-constructive:disabled:active,.mw-ui-button.mw-ui-constructive:disabled.mw-ui-checked{box-shadow:none}.mw-ui-button.mw-ui-constructive.mw-ui-quiet{color:#555}.mw-ui-button.mw-ui-constructive.mw-ui-quiet:hover,.mw-ui-button.mw-ui-constructive.mw-ui-quiet:focus{background:transparent;color:#00af89}.mw-ui-button.mw-ui-constructive.mw-ui-quiet:active,.mw-ui-button.mw-ui-constructive.mw-ui-quiet.mw-ui-checked{color:#008C6D}.mw-ui-button.mw-ui-constructive.mw-ui-quiet:disabled{color:#CCC}.mw-ui-button.mw-ui-destructive{background:#d11d13;color:#fff;border:1px solid #d11d13;text-shadow:0 1px rgba(0,0,0,0.1)}.mw-ui-button.mw-ui-destructive:hover{background-color:#A7170F}.mw-ui-button.mw-ui-destructive:focus{border-color:#fff;box-shadow:0 0 0 1px #A7170F;outline:none}.mw-ui-button.mw-ui-destructive:focus::-moz-focus-inner{border-color:transparent}.mw-ui-button.mw-ui-destructive:active,.mw-ui-button.mw-ui-destructive.mw-ui-checked{background:#A7170F;box-shadow:none}.mw-ui-button.mw-ui-destructive:disabled{background:#DDD;border-color:#DDD}.mw-ui-button.mw-ui-destructive:disabled:hover,.mw-ui-button.mw-ui-destructive:disabled:active,.mw-ui-button.mw-ui-destructive:disabled.mw-ui-checked{box-shadow:none}.mw-ui-button.mw-ui-destructive.mw-ui-quiet{color:#555}.mw-ui-button.mw-ui-destructive.mw-ui-quiet:hover,.mw-ui-button.mw-ui-destructive.mw-ui-quiet:focus{background:transparent;color:#d11d13}.mw-ui-button.mw-ui-destructive.mw-ui-quiet:active,.mw-ui-button.mw-ui-destructive.mw-ui-quiet.mw-ui-checked{color:#A7170F}.mw-ui-button.mw-ui-destructive.mw-ui-quiet:disabled{color:#CCC}.mw-ui-button.mw-ui-quiet{background:transparent;border:none;text-shadow:none;color:#555}.mw-ui-button.mw-ui-quiet:hover,.mw-ui-button.mw-ui-quiet:focus{background:transparent;color:#555}.mw-ui-button.mw-ui-quiet:active,.mw-ui-button.mw-ui-quiet.mw-ui-checked{color:#777}.mw-ui-button.mw-ui-quiet:disabled{color:#CCC}.mw-ui-button.mw-ui-quiet:hover,.mw-ui-button.mw-ui-quiet:focus{box-shadow:none}.mw-ui-button.mw-ui-quiet:active,.mw-ui-button.mw-ui-quiet:disabled{background:transparent}a.mw-ui-button{text-decoration:none}a.mw-ui-button:hover,a.mw-ui-button:focus{text-decoration:none}.mw-ui-button-group > *{min-width:48px;border-radius:0;float:left}.mw-ui-button-group > *:first-child{border-top-left-radius:2px;border-bottom-left-radius:2px}.mw-ui-button-group > *:not(:first-child){border-left:none}.mw-ui-button-group > *:last-child{border-top-right-radius:2px;border-bottom-right-radius:2px}
.mw-ui-icon{position:relative;min-height:1.5em;min-width:1.5em}.mw-ui-icon.mw-ui-icon-element{text-indent:-999px;overflow:hidden;width:3.5em;min-width:3.5em;max-width:3.5em}.mw-ui-icon.mw-ui-icon-element:before{left:0;right:0;position:absolute;margin:0 1em}.mw-ui-icon.mw-ui-icon-before:before,.mw-ui-icon.mw-ui-icon-element:before{background-position:50% 50%;float:left;display:block;background-repeat:no-repeat;background-size:100% auto;min-height:1.5em;content:''}.mw-ui-icon.mw-ui-icon-before:before{position:relative;width:1.5em;margin-right:1em}
.wp-teahouse-question-form{position:absolute;margin-left:auto;margin-right:auto;background-color:#f4f3f0;border:1px solid #a7d7f9;padding:1em}#wp-th-question-ask{float:right}.wp-teahouse-ask a.external{background-image:none !important}.wp-teahouse-respond-form{position:absolute;margin-left:auto;margin-right:auto;background-color:#f4f3f0;border:1px solid #a7d7f9;padding:1em}.wp-th-respond{float:right}.wp-teahouse-respond a.external{background-image:none !important}
/* cache key: enwiki:resourceloader:filter:minify-css:7:8614dfa7ef847fc9bfcc2d1c9f720197 */
.referencetooltip{position:absolute;list-style:none;list-style-image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip li{border:#080086 2px solid;max-width:260px;padding:10px 8px 13px 8px;margin:0px;background-color:#F7F7F7;box-shadow:2px 4px 2px rgba(0,0,0,0.3);-moz-box-shadow:2px 4px 2px rgba(0,0,0,0.3);-webkit-box-shadow:2px 4px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;width:0px;background-color:transparent;box-shadow:none;-moz-box-shadow:none;-webkit-box-shadow:none;border-top:12px #080086 solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent solid;border-left:5px transparent solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;box-shadow:none;-moz-box-shadow:none;-webkit-box-shadow:none;height:auto;width:auto;margin:auto;padding:0;position:static}.RTflipped{padding-top:13px}.referencetooltip.RTflipped li+li{position:absolute;top:2px;border-top:0;border-bottom:12px #080086 solid}.referencetooltip.RTflipped li+li::after{border-top:0;border-bottom:8px #F7F7F7 solid;position:absolute;margin-top:7px}.RTsettings{float:right;height:24px;width:24px;cursor:pointer;background-image:url(//upload.wikimedia.org/wikipedia/commons/thumb/7/77/Gear_icon.svg/24px-Gear_icon.svg.png);background-image:linear-gradient(transparent,transparent),url(//upload.wikimedia.org/wikipedia/commons/7/77/Gear_icon.svg);margin-top:-9px;margin-right:-7px;-webkit-transition:opacity 0.15s;-moz-transition:opacity 0.15s;-o-transition:opacity 0.15s;-ms-transition:opacity 0.15s;transition:opacity 0.15s;opacity:0.6;filter:alpha(opacity=60)}.RTsettings:hover{opacity:1;filter:alpha(opacity=100)}.RTTarget{border:#080086 2px solid}
.skin-vector li.GA,.skin-monobook li.GA,.skin-modern li.GA{list-style-image:url(//upload.wikimedia.org/wikipedia/commons/4/42/Monobook-bullet-ga.png)} .skin-vector li.FA,.skin-monobook li.FA{list-style-image:url(//upload.wikimedia.org/wikipedia/commons/d/d4/Monobook-bullet-star.png)}.skin-modern li.FA{list-style-image:url(//upload.wikimedia.org/wikipedia/commons/thumb/2/2c/Modern-bullet-star.svg/9px-Modern-bullet-star.svg.png)}
/* cache key: enwiki:resourceloader:filter:minify-css:7:22ca6c0fc9d0923a196f8a3aec796994 */
#p-lang .uls-settings-trigger{background:transparent url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA4AAAAgCAQAAACI54EcAAAAAnNCSVQICFXsRgQAAAAJcEhZcwAADdcAAA3XAUIom3gAAAAZdEVYdFNvZnR3YXJlAHd3dy5pbmtzY2FwZS5vcmeb7jwaAAABWklEQVQoz42RwWrCQBBAc/PkyXiQfpEXobKzEsipCkKh5CBUhBBmaWrw6j/oIQr6VeaSXzDpZDbZ1CWVMhBm5zGT2X1O6fwdv1L0saTwLajmar0d4JHh6XuEofqooVpiQcU7ozbeGWJklXVEGrrcWWKOCUXOeYEuQeXhQaNdv/rPrl/jFH3HjEnM1klTa2FsYNzCBV45zfa9Cu17mPH5gm903A7rhW60d0Rf7opf9D03nVf50jCwyjxHrZvnCzCkR0sZndFVK/y0Hl7NGC46rTxV9hRKH0oope0T5nL9OhDHCsJpOhKhaHyKJRRUvDMyIbRPiB7LdWifnsudJeSQUOScF17lU3pw0GjCPid9jWUqfceMMT6pu6610PiE2ECxgCun2Zh9jnuQ8fkiK58wrBe60d4RfXWf9ik2XVeR2icEFuA5svEJgQinI5kyOnuuWAnbJ8z42f7r8wfhovZYX3llNQAAAABJRU5ErkJggg==) no-repeat right top;background:transparent url(https://en.wikipedia.org/static/1.26wmf19/extensions/UniversalLanguageSelector/resources/images/cog-sprite.png?fae8e) no-repeat right top!ie;background-image:-webkit-linear-gradient(transparent,transparent),url(data:image/svg+xml,%3C%3Fxml%20version%3D%221.0%22%20encoding%3D%22UTF-8%22%3F%3E%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20xmlns%3Axlink%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2Fxlink%22%20width%3D%2214%22%20height%3D%2232%22%3E%3Cdefs%3E%3Cpath%20d%3D%22M14%209.3V6.73l-1.575-.264c-.117-.44-.292-.848-.496-1.2l.93-1.285-1.81-1.84-1.31.908c-.38-.205-.79-.38-1.196-.497L8.284%201H5.716l-.263%201.578c-.437.117-.816.293-1.196.497L2.975%202.17%201.137%203.98l.934%201.287c-.2.38-.376.79-.493%201.228L0%206.73V9.3l1.575.264c.117.438.292.818.496%201.198l-.93%201.315L2.95%2013.89l1.312-.938c.38.205.787.38%201.224.497L5.746%2015h2.566l.263-1.578c.408-.117.817-.293%201.196-.497l1.315.935%201.81-1.812-.935-1.315c.203-.38.38-.76.495-1.2L14%209.303zm-7%201.404c-1.488%200-2.683-1.2-2.683-2.69S5.542%205.327%207%205.327c1.458%200%202.683%201.198%202.683%202.69%200%201.49-1.195%202.688-2.683%202.688z%22%20id%3D%22a%22%2F%3E%3C%2Fdefs%3E%3Cuse%20xlink%3Ahref%3D%22%23a%22%20fill%3D%22%23808080%22%2F%3E%3Cuse%20transform%3D%22translate%280%2016%29%22%20xlink%3Ahref%3D%22%23a%22%20fill%3D%22%23555%22%2F%3E%3C%2Fsvg%3E%0A);background-image:-webkit-linear-gradient(transparent,transparent),url(https://en.wikipedia.org/static/1.26wmf19/extensions/UniversalLanguageSelector/resources/images/cog-sprite.svg?624e4)!ie;background-image:linear-gradient(transparent,transparent),url(data:image/svg+xml,%3C%3Fxml%20version%3D%221.0%22%20encoding%3D%22UTF-8%22%3F%3E%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20xmlns%3Axlink%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2Fxlink%22%20width%3D%2214%22%20height%3D%2232%22%3E%3Cdefs%3E%3Cpath%20d%3D%22M14%209.3V6.73l-1.575-.264c-.117-.44-.292-.848-.496-1.2l.93-1.285-1.81-1.84-1.31.908c-.38-.205-.79-.38-1.196-.497L8.284%201H5.716l-.263%201.578c-.437.117-.816.293-1.196.497L2.975%202.17%201.137%203.98l.934%201.287c-.2.38-.376.79-.493%201.228L0%206.73V9.3l1.575.264c.117.438.292.818.496%201.198l-.93%201.315L2.95%2013.89l1.312-.938c.38.205.787.38%201.224.497L5.746%2015h2.566l.263-1.578c.408-.117.817-.293%201.196-.497l1.315.935%201.81-1.812-.935-1.315c.203-.38.38-.76.495-1.2L14%209.303zm-7%201.404c-1.488%200-2.683-1.2-2.683-2.69S5.542%205.327%207%205.327c1.458%200%202.683%201.198%202.683%202.69%200%201.49-1.195%202.688-2.683%202.688z%22%20id%3D%22a%22%2F%3E%3C%2Fdefs%3E%3Cuse%20xlink%3Ahref%3D%22%23a%22%20fill%3D%22%23808080%22%2F%3E%3Cuse%20transform%3D%22translate%280%2016%29%22%20xlink%3Ahref%3D%22%23a%22%20fill%3D%22%23555%22%2F%3E%3C%2Fsvg%3E%0A);background-image:linear-gradient(transparent,transparent),url(https://en.wikipedia.org/static/1.26wmf19/extensions/UniversalLanguageSelector/resources/images/cog-sprite.svg?624e4)!ie;height:16px;width:14px;float:right;cursor:pointer}.skin-vector #p-lang .uls-settings-trigger{ margin-top:3px}#p-lang .uls-settings-trigger:hover{background-position:right -16px}</style><style>
#mw-wlheader-showupdated,#mw-wlheader-bold,#mw-wlheader-green,#mw-watchlist-resetbutton{display:none}.updatedmarker{background-color:transparent;color:#006400}.mw-changeslist-line-watched .mw-title,.mw-enhanced-watched .mw-enhanced-rc-time{font-weight:normal}
.suggestions a.mw-searchSuggest-link,.suggestions a.mw-searchSuggest-link:hover,.suggestions a.mw-searchSuggest-link:active,.suggestions a.mw-searchSuggest-link:focus{color:black;text-decoration:none}.suggestions-result-current a.mw-searchSuggest-link,.suggestions-result-current a.mw-searchSuggest-link:hover,.suggestions-result-current a.mw-searchSuggest-link:active,.suggestions-result-current a.mw-searchSuggest-link:focus{color:white}.suggestions a.mw-searchSuggest-link .special-query{ overflow:hidden;-o-text-overflow:ellipsis; text-overflow:ellipsis;white-space:nowrap}
.mw-mmv-overlay{position:fixed;top:0px;left:0px;right:0px;bottom:0px;z-index:1000;background-color:#000000}body.mw-mmv-lightbox-open{overflow-y:auto}body.mw-mmv-lightbox-open #mw-page-base,body.mw-mmv-lightbox-open #mw-head-base,body.mw-mmv-lightbox-open #mw-navigation,body.mw-mmv-lightbox-open #content,body.mw-mmv-lightbox-open #footer,body.mw-mmv-lightbox-open #globalWrapper // monobook{ display:none}body.mw-mmv-lightbox-open > *{ display:none}body.mw-mmv-lightbox-open > .mw-mmv-overlay,body.mw-mmv-lightbox-open > .mw-mmv-wrapper{display:block}.mw-mmv-filepage-buttons{margin-top:5px}.mw-mmv-filepage-buttons .mw-mmv-view-expanded,.mw-mmv-filepage-buttons .mw-mmv-view-config{display:block}.mw-mmv-filepage-buttons .mw-mmv-view-expanded.mw-ui-icon:before{background-image:url(data:image/svg+xml,%3C%3Fxml%20version%3D%221.0%22%20encoding%3D%22UTF-8%22%20standalone%3D%22no%22%3F%3E%0A%3C%21--%20Created%20with%20Inkscape%20%28http%3A%2F%2Fwww.inkscape.org%2F%29%20--%3E%0A%0A%3Csvg%0A%20%20%20xmlns%3Adc%3D%22http%3A%2F%2Fpurl.org%2Fdc%2Felements%2F1.1%2F%22%0A%20%20%20xmlns%3Acc%3D%22http%3A%2F%2Fcreativecommons.org%2Fns%23%22%0A%20%20%20xmlns%3Ardf%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2F02%2F22-rdf-syntax-ns%23%22%0A%20%20%20xmlns%3Asvg%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%0A%20%20%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%0A%20%20%20version%3D%221.1%22%0A%20%20%20width%3D%22100%25%22%0A%20%20%20height%3D%22100%25%22%0A%20%20%20viewBox%3D%220%200%201024%20768%22%0A%20%20%20id%3D%22Layer_1%22%0A%20%20%20xml%3Aspace%3D%22preserve%22%3E%3Cmetadata%0A%20%20%20%20%20id%3D%22metadata17%22%3E%3Crdf%3ARDF%3E%3Ccc%3AWork%0A%20%20%20%20%20%20%20%20%20rdf%3Aabout%3D%22%22%3E%3Cdc%3Aformat%3Eimage%2Fsvg%2Bxml%3C%2Fdc%3Aformat%3E%3Cdc%3Atype%0A%20%20%20%20%20%20%20%20%20%20%20rdf%3Aresource%3D%22http%3A%2F%2Fpurl.org%2Fdc%2Fdcmitype%2FStillImage%22%20%2F%3E%3Cdc%3Atitle%3E%3C%2Fdc%3Atitle%3E%3C%2Fcc%3AWork%3E%3C%2Frdf%3ARDF%3E%3C%2Fmetadata%3E%3Cdefs%0A%20%20%20%20%20id%3D%22defs15%22%20%2F%3E%3Cg%0A%20%20%20%20%20id%3D%22g3%22%3E%3Cpolygon%0A%20%20%20%20%20%20%20points%3D%22851.2%2C71.6%20690.7%2C232.1%20650.6%2C191.8%20641%2C356.6%20805.8%2C347.3%20765.5%2C306.9%20926%2C146.4%20984.5%2C204.9%20997.6%2C0%20792.7%2C13.1%20%22%0A%20%20%20%20%20%20%20id%3D%22polygon5%22%0A%20%20%20%20%20%20%20style%3D%22fill%3A%23777777%22%20%2F%3E%3Cpolygon%0A%20%20%20%20%20%20%20points%3D%22769.6%2C89.3%20611.9%2C89.3%20682.8%2C160.1%20690.7%2C167.6%20%22%0A%20%20%20%20%20%20%20id%3D%22polygon7%22%0A%20%20%20%20%20%20%20style%3D%22fill%3A%23777777%22%20%2F%3E%3Cpath%0A%20%20%20%20%20%20%20d%3D%22m%20643.6%2C402.2%20-51.2%2C3%203%2C-51.2%209.4%2C-164.4%205.8%2C-100.3%20H%2026.4%20V%20768%20H%20909.5%20V%20387%20l%20-100.9%2C5.8%20-165%2C9.4%20z%20M%20813.9%2C678%20H%20113.6%20l%20207.2%2C-270.2%2031.5%2C-12.9%20195.7%2C204.9%20105.9%2C-63.2%20159.8%2C140.8%200.2%2C0.6%200%2C0%20z%22%0A%20%20%20%20%20%20%20id%3D%22path9%22%0A%20%20%20%20%20%20%20style%3D%22fill%3A%23777777%22%20%2F%3E%3Cpolygon%0A%20%20%20%20%20%20%20points%3D%22909.5%2C386.1%20909.5%2C228%20830.4%2C306.9%20838.2%2C314.8%20%22%0A%20%20%20%20%20%20%20id%3D%22polygon11%22%0A%20%20%20%20%20%20%20style%3D%22fill%3A%23777777%22%20%2F%3E%3C%2Fg%3E%3C%2Fsvg%3E);background-image:url(https://en.wikipedia.org/static/1.26wmf21/extensions/MultimediaViewer/resources/mmv/img/expand.svg?09b49)!ie}.mw-mmv-filepage-buttons .mw-mmv-view-config.mw-ui-icon:before{background-image:url(data:image/svg+xml,%3C%3Fxml%20version%3D%221.0%22%20encoding%3D%22UTF-8%22%20standalone%3D%22no%22%3F%3E%0A%3C%21--%20Created%20with%20Inkscape%20%28http%3A%2F%2Fwww.inkscape.org%2F%29%20--%3E%0A%0A%3Csvg%0A%20%20%20xmlns%3Adc%3D%22http%3A%2F%2Fpurl.org%2Fdc%2Felements%2F1.1%2F%22%0A%20%20%20xmlns%3Acc%3D%22http%3A%2F%2Fcreativecommons.org%2Fns%23%22%0A%20%20%20xmlns%3Ardf%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2F02%2F22-rdf-syntax-ns%23%22%0A%20%20%20xmlns%3Asvg%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%0A%20%20%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%0A%20%20%20version%3D%221.1%22%0A%20%20%20width%3D%22100%25%22%0A%20%20%20height%3D%22100%25%22%0A%20%20%20viewBox%3D%220%200%201024%20768%22%0A%20%20%20id%3D%22Layer_1%22%0A%20%20%20xml%3Aspace%3D%22preserve%22%3E%3Cmetadata%0A%20%20%20%20%20id%3D%22metadata9%22%3E%3Crdf%3ARDF%3E%3Ccc%3AWork%0A%20%20%20%20%20%20%20%20%20rdf%3Aabout%3D%22%22%3E%3Cdc%3Aformat%3Eimage%2Fsvg%2Bxml%3C%2Fdc%3Aformat%3E%3Cdc%3Atype%0A%20%20%20%20%20%20%20%20%20%20%20rdf%3Aresource%3D%22http%3A%2F%2Fpurl.org%2Fdc%2Fdcmitype%2FStillImage%22%20%2F%3E%3Cdc%3Atitle%3E%3C%2Fdc%3Atitle%3E%3C%2Fcc%3AWork%3E%3C%2Frdf%3ARDF%3E%3C%2Fmetadata%3E%3Cdefs%0A%20%20%20%20%20id%3D%22defs7%22%20%2F%3E%3Cpath%0A%20%20%20%20%20d%3D%22M%20897%2C454.6%20V%20313.4%20L%20810.4%2C299%20c%20-6.4%2C-23.3%20-16%2C-45.7%20-27.3%2C-65.8%20L%20833.6%2C161.8%20734.2%2C61.6%20662.8%2C112.1%20C%20641.9%2C100.9%20620.3%2C91.2%20597%2C84.8%20L%20582.6%2C-1%20H%20441.4%20L%20427%2C85.6%20c%20-23.3%2C6.4%20-45.7%2C16%20-65.8%2C27.3%20L%20289.8%2C62.4%20189.5%2C161.9%20240%2C233.3%20c%20-11.2%2C20.9%20-20.9%2C42.5%20-27.3%2C66.6%20L%20127%2C313.4%20v%20141.2%20l%2085.8%2C14.4%20c%206.4%2C23.3%2016%2C45.7%2027.3%2C66.6%20l%20-50.5%2C71.4%2099.5%2C99.5%2071.4%2C-50.5%20c%2020.9%2C11.2%2042.5%2C20.9%2066.6%2C27.3%20l%2014.4%2C85.8%20h%20141.2%20l%2014.4%2C-86.6%20c%2023.3%2C-6.4%2045.7%2C-16%2065.8%2C-27.3%20l%2071.4%2C50.5%2099.5%2C-99.5%20-50.5%2C-71.4%20c%2011.2%2C-20.9%2020.9%2C-42.5%2027.3%2C-66.6%20L%20897%2C454.6%20z%20m%20-385%2C77%20C%20430.2%2C531.6%20364.4%2C465%20364.4%2C384%20364.4%2C302.2%20431%2C236.4%20512%2C236.4%20c%2081%2C0%20147.6%2C65.8%20147.6%2C147.6%200%2C81.8%20-65.8%2C147.6%20-147.6%2C147.6%20z%22%0A%20%20%20%20%20id%3D%22path3%22%0A%20%20%20%20%20style%3D%22fill%3A%23777777%22%20%2F%3E%3C%2Fsvg%3E);background-image:url(https://en.wikipedia.org/static/1.26wmf21/extensions/MultimediaViewer/resources/mmv/img/gear_gray.svg?ea8fa)!ie;opacity:0.75}.mw-mmv-filepage-buttons .mw-mmv-view-config.mw-ui-icon:before:hover{opacity:1}</style><style>
#mw-wlheader-showupdated,#mw-wlheader-green{display:inline}#mw-watchlist-resetbutton{display:block}li.mw-changeslist-line-watched,li.mw-history-line-updated{list-style-image:url(//upload.wikimedia.org/wikipedia/commons/1/19/ChangedBulletVector.svg);list-style-image:url(//upload.wikimedia.org/wikipedia/commons/c/c2/ChangedBulletVector.png)\9} td.mw-enhanced-rc,.mw-enhanced-rc-time{font-family:monospace,monospace}.mw-enhanced-rc-nested{background-position:0 3px}.mw-enhancedchanges-arrow-space{background-position:center top}.mw-enhanced-rc-nested,.mw-enhancedchanges-arrow-space{background-repeat:no-repeat;background-image:url(//upload.wikimedia.org/wikipedia/commons/9/90/Vector-bullet-icon.png);background-image:-moz-linear-gradient(transparent,transparent),url(//upload.wikimedia.org/wikipedia/commons/b/bf/Vector-bullet-icon.svg);background-image:-webkit-linear-gradient(transparent,transparent),url(//upload.wikimedia.org/wikipedia/commons/b/bf/Vector-bullet-icon.svg);background-image:linear-gradient(transparent,transparent),url(//upload.wikimedia.org/wikipedia/commons/b/bf/Vector-bullet-icon.svg)}.mw-enhanced-watched .mw-enhanced-rc-nested,.mw-changeslist-line-watched .mw-enhancedchanges-arrow-space{background-image:url(//upload.wikimedia.org/wikipedia/commons/c/c2/ChangedBulletVector.png);background-image:-moz-linear-gradient(transparent,transparent),url(//upload.wikimedia.org/wikipedia/commons/1/19/ChangedBulletVector.svg);background-image:-webkit-linear-gradient(transparent,transparent),url(//upload.wikimedia.org/wikipedia/commons/1/19/ChangedBulletVector.svg);background-image:linear-gradient(transparent,transparent),url(//upload.wikimedia.org/wikipedia/commons/1/19/ChangedBulletVector.svg)}.mw-changeslist-line-not-watched .mw-collapsible-arrow.mw-collapsible-toggle-collapsed{background-position:center top;background-image:url(//upload.wikimedia.org/wikipedia/commons/b/bc/Vector_right_arrow_link.png);background-image:-moz-linear-gradient(transparent,transparent),url(//upload.wikimedia.org/wikipedia/commons/3/39/Vector_right_arrow_link.svg);background-image:-webkit-linear-gradient(transparent,transparent),url(//upload.wikimedia.org/wikipedia/commons/3/39/Vector_right_arrow_link.svg);background-image:linear-gradient(transparent,transparent),url(//upload.wikimedia.org/wikipedia/commons/3/39/Vector_right_arrow_link.svg)}.mw-changeslist-line-not-watched .mw-collapsible-arrow.mw-collapsible-toggle-expanded{background-position:center top;background-image:url(//upload.wikimedia.org/wikipedia/commons/2/27/Vector_down_arrow_link.png);background-image:-moz-linear-gradient(transparent,transparent),url(//upload.wikimedia.org/wikipedia/commons/d/db/Vector_down_arrow_link.svg);background-image:-webkit-linear-gradient(transparent,transparent),url(//upload.wikimedia.org/wikipedia/commons/d/db/Vector_down_arrow_link.svg);background-image:linear-gradient(transparent,transparent),url(//upload.wikimedia.org/wikipedia/commons/d/db/Vector_down_arrow_link.svg)}.mw-changeslist-line-watched .mw-collapsible-arrow.mw-collapsible-toggle-collapsed{background-image:url(//upload.wikimedia.org/wikipedia/commons/a/af/Vector_right_arrow_changed.png);background-image:-moz-linear-gradient(transparent,transparent),url(//upload.wikimedia.org/wikipedia/commons/0/03/Vector_right_arrow_changed.svg);background-image:-webkit-linear-gradient(transparent,transparent),url(//upload.wikimedia.org/wikipedia/commons/0/03/Vector_right_arrow_changed.svg);background-image:linear-gradient(transparent,transparent),url(//upload.wikimedia.org/wikipedia/commons/0/03/Vector_right_arrow_changed.svg)}.mw-changeslist-line-watched .mw-collapsible-arrow.mw-collapsible-toggle-expanded{background-image:url(//upload.wikimedia.org/wikipedia/commons/e/e5/Vector_down_arrow_changed.png);background-image:-moz-linear-gradient(transparent,transparent),url(//upload.wikimedia.org/wikipedia/commons/1/12/Vector_down_arrow_changed.svg);background-image:-webkit-linear-gradient(transparent,transparent),url(//upload.wikimedia.org/wikipedia/commons/1/12/Vector_down_arrow_changed.svg);background-image:linear-gradient(transparent,transparent),url(//upload.wikimedia.org/wikipedia/commons/1/12/Vector_down_arrow_changed.svg)}</style><meta name="ResourceLoaderDynamicStyles" content="">
<link rel="stylesheet" href="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/load(2).php">
<style>a:lang(ar),a:lang(kk-arab),a:lang(mzn),a:lang(ps),a:lang(ur){text-decoration:none}</style>
<script async="" src="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/load(3).php"></script>
<meta name="generator" content="MediaWiki 1.26wmf21">
<link rel="alternate" href="android-app://org.wikipedia/http/en.m.wikipedia.org/wiki/Stochastic_gradient_descent">
<link rel="alternate" type="application/x-wiki" title="Edit this page" href="https://en.wikipedia.org/w/index.php?title=Stochastic_gradient_descent&action=edit">
<link rel="edit" title="Edit this page" href="https://en.wikipedia.org/w/index.php?title=Stochastic_gradient_descent&action=edit">
<link rel="apple-touch-icon" href="https://en.wikipedia.org/static/apple-touch/wikipedia.png">
<link rel="shortcut icon" href="https://en.wikipedia.org/static/favicon/wikipedia.ico">
<link rel="search" type="application/opensearchdescription+xml" href="https://en.wikipedia.org/w/opensearch_desc.php" title="Wikipedia (en)">
<link rel="EditURI" type="application/rsd+xml" href="https://en.wikipedia.org/w/api.php?action=rsd">
<link rel="copyright" href="https://creativecommons.org/licenses/by-sa/3.0/">
<link rel="alternate" type="application/atom+xml" title="Wikipedia Atom feed" href="https://en.wikipedia.org/w/index.php?title=Special:RecentChanges&feed=atom">
<link rel="canonical" href="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/Stochastic gradient descent - Wikipedia, the free encyclopedia.html">
<link rel="dns-prefetch" href="https://meta.wikimedia.org/">
<!--[if lt IE 7]><style type="text/css">body{behavior:url("/w/static/1.26wmf21/skins/Vector/csshover.min.htc")}</style><![endif]-->
<style type="text/css"></style><script src="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/load(4).php"></script></head>
<body class="mediawiki ltr sitedir-ltr ns-0 ns-subject page-Stochastic_gradient_descent skin-vector action-view">
		<div id="mw-page-base" class="noprint"></div>
		<div id="mw-head-base" class="noprint"></div>
		<div id="content" class="mw-body" role="main">
			<a id="top"></a>

							<div id="siteNotice"><div id="centralNotice"></div><!-- CentralNotice --></div>
						<div class="mw-indicators">
</div>
			<h1 id="firstHeading" class="firstHeading" lang="en">Stochastic gradient descent</h1>
									<div id="bodyContent" class="mw-body-content">
									<div id="siteSub">From Wikipedia, the free encyclopedia</div>
								<div id="contentSub"></div>
												<div id="jump-to-nav" class="mw-jump">
					Jump to:					<a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#mw-head">navigation</a>, 					<a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#p-search">search</a>
				</div>
				<div id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><p><b>Stochastic gradient descent</b> is a <a href="https://en.wikipedia.org/wiki/Gradient_descent_optimization" title="Gradient descent optimization" class="mw-redirect">gradient descent optimization</a> <a href="https://en.wikipedia.org/wiki/Iterative_method" title="Iterative method">method</a> for minimizing an <a href="https://en.wikipedia.org/wiki/Objective_function" title="Objective function" class="mw-redirect">objective function</a> that is written as a sum of differentiable functions.</p>
<p></p>
<div id="toc" class="toc">
<div id="toctitle">
<h2>Contents</h2>
<span class="toctoggle">&nbsp;[<a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#" id="togglelink">hide</a>]&nbsp;</span></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Background"><span class="tocnumber">1</span> <span class="toctext">Background</span></a></li>
<li class="toclevel-1 tocsection-2"><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Iterative_method"><span class="tocnumber">2</span> <span class="toctext">Iterative method</span></a></li>
<li class="toclevel-1 tocsection-3"><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Example"><span class="tocnumber">3</span> <span class="toctext">Example</span></a></li>
<li class="toclevel-1 tocsection-4"><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Applications"><span class="tocnumber">4</span> <span class="toctext">Applications</span></a></li>
<li class="toclevel-1 tocsection-5"><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Extensions_and_variants"><span class="tocnumber">5</span> <span class="toctext">Extensions and variants</span></a>
<ul>
<li class="toclevel-2 tocsection-6"><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Momentum"><span class="tocnumber">5.1</span> <span class="toctext">Momentum</span></a></li>
<li class="toclevel-2 tocsection-7"><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Averaging"><span class="tocnumber">5.2</span> <span class="toctext">Averaging</span></a></li>
<li class="toclevel-2 tocsection-8"><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#AdaGrad"><span class="tocnumber">5.3</span> <span class="toctext">AdaGrad</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-9"><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Notes"><span class="tocnumber">6</span> <span class="toctext">Notes</span></a></li>
<li class="toclevel-1 tocsection-10"><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#See_also"><span class="tocnumber">7</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1 tocsection-11"><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#References"><span class="tocnumber">8</span> <span class="toctext">References</span></a></li>
<li class="toclevel-1 tocsection-12"><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Further_reading"><span class="tocnumber">9</span> <span class="toctext">Further reading</span></a></li>
<li class="toclevel-1 tocsection-13"><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Software"><span class="tocnumber">10</span> <span class="toctext">Software</span></a></li>
<li class="toclevel-1 tocsection-14"><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#External_links"><span class="tocnumber">11</span> <span class="toctext">External links</span></a></li>
</ul>
</div>
<p></p>
<h2><span class="mw-headline" id="Background">Background</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Stochastic_gradient_descent&action=edit&section=1" title="Edit section: Background">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="hatnote relarticle mainarticle">Main article: <a href="https://en.wikipedia.org/wiki/M-estimation" title="M-estimation" class="mw-redirect">M-estimation</a></div>
<div class="hatnote">See also: <a href="https://en.wikipedia.org/wiki/Estimating_equation" title="Estimating equation" class="mw-redirect">Estimating equation</a></div>
<p>Both <a href="https://en.wikipedia.org/wiki/Statistics" title="Statistics">statistical</a> <a href="https://en.wikipedia.org/wiki/M-estimation" title="M-estimation" class="mw-redirect">estimation</a> and <a href="https://en.wikipedia.org/wiki/Machine_learning" title="Machine learning">machine learning</a> consider the problem of minimizing an <a href="https://en.wikipedia.org/wiki/Objective_function" title="Objective function" class="mw-redirect">objective function</a> that has the form of a sum:</p>
<dl>
<dd><img class="mwe-math-fallback-image-inline tex" alt="Q(w) = \sum_{i=1}^n Q_i(w)," src="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/ae2c218f8312123cb7d3446f5d0cab54.png"></dd>
</dl>
<p>where the <a href="https://en.wikipedia.org/wiki/Parametric_statistics" title="Parametric statistics">parameter</a> <img class="mwe-math-fallback-image-inline tex" alt="w^*" src="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/5a89237762874d6615620978742a8f36.png"> which minimizes <img class="mwe-math-fallback-image-inline tex" alt="Q(w)" src="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/442953735b7d346fc2701b284c36ab58.png"> is to be <a href="https://en.wikipedia.org/wiki/Estimator" title="Estimator">estimated</a>. Each summand function <img class="mwe-math-fallback-image-inline tex" alt="Q_i" src="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/85ba8048979d3422abccc527b2d1e78d.png"> is typically associated with the <img class="mwe-math-fallback-image-inline tex" alt="i" src="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/865c0c0b4ab0e063e5caa3387c1a8741.png">-th <a href="https://en.wikipedia.org/wiki/Observation" title="Observation">observation</a> in the <a href="https://en.wikipedia.org/wiki/Data_set" title="Data set">data set</a> (used for training).</p>
<p>In classical statistics, sum-minimization problems arise in <a href="https://en.wikipedia.org/wiki/Least_squares" title="Least squares">least squares</a> and in <a href="https://en.wikipedia.org/wiki/Maximum-likelihood_estimation" title="Maximum-likelihood estimation" class="mw-redirect">maximum-likelihood estimation</a> (for independent observations). The general class of estimators that arise as minimizers of sums are called <a href="https://en.wikipedia.org/wiki/M-estimator" title="M-estimator">M-estimators</a>. However, in statistics, it has been long recognized that requiring even local minimization is too restrictive for some problems of maximum-likelihood estimation, as shown for example by Thomas Ferguson's example.<sup id="cite_ref-1" class="reference"><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#cite_note-1"><span>[</span>1<span>]</span></a></sup> Therefore, contemporary statistical theorists often consider <a href="https://en.wikipedia.org/wiki/Stationary_point" title="Stationary point">stationary points</a> of the <a href="https://en.wikipedia.org/wiki/Likelihood_function" title="Likelihood function">likelihood function</a> (or zeros of its derivative, the <a href="https://en.wikipedia.org/wiki/Score_(statistics)" title="Score (statistics)">score function</a>, and other <a href="https://en.wikipedia.org/wiki/Estimating_equations" title="Estimating equations">estimating equations</a>).</p>
<p>The sum-minimization problem also arises for <a href="https://en.wikipedia.org/wiki/Empirical_risk_minimization" title="Empirical risk minimization">empirical risk minimization</a>: In this case, <img class="mwe-math-fallback-image-inline tex" alt="Q_i(w)" src="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/3f0e952b1180cf5e3df480a418ff4df0.png"> is the value of the <a href="https://en.wikipedia.org/wiki/Loss_function" title="Loss function">loss function</a> at <img class="mwe-math-fallback-image-inline tex" alt="i" src="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/865c0c0b4ab0e063e5caa3387c1a8741.png">-th example, and <img class="mwe-math-fallback-image-inline tex" alt="Q(w)" src="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/442953735b7d346fc2701b284c36ab58.png"> is the empirical risk.</p>
<p>When used to minimize the above function, a standard (or "batch") <a href="https://en.wikipedia.org/wiki/Gradient_descent" title="Gradient descent">gradient descent</a> method would perform the following iterations&nbsp;:</p>
<dl>
<dd><img class="mwe-math-fallback-image-inline tex" alt="w := w - \eta \nabla Q(w) = w - \eta \sum_{i=1}^n \nabla Q_i(w)," src="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/fd0c33cb743db74df34a54e2b41db98f.png"></dd>
</dl>
<p>where <img class="mwe-math-fallback-image-inline tex" alt="\eta" src="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/7174cbd6aeaaa56e37102b72386bb2b9.png"> is a step size (sometimes called the <i>learning rate</i> in machine learning).</p>
<p>In many cases, the summand functions have a simple form that enables inexpensive evaluations of the sum-function and the sum gradient. For example, in statistics, <a href="https://en.wikipedia.org/wiki/Exponential_families" title="Exponential families" class="mw-redirect">one-parameter exponential families</a> allow economical function-evaluations and gradient-evaluations.</p>
<p>However, in other cases, evaluating the sum-gradient may require expensive evaluations of the gradients from all summand functions. When the training set is enormous and no simple formulas exist, evaluating the sums of gradients becomes very expensive, because evaluating the gradient requires evaluating all the summand functions' gradients. To economize on the computational cost at every iteration, stochastic gradient descent <a href="https://en.wikipedia.org/wiki/Sampling_(statistics)" title="Sampling (statistics)">samples</a> a subset of summand functions at every step. This is very effective in the case of large-scale machine learning problems.<sup id="cite_ref-2" class="reference"><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#cite_note-2"><span>[</span>2<span>]</span></a></sup></p>
<h2><span class="mw-headline" id="Iterative_method">Iterative method</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Stochastic_gradient_descent&action=edit&section=2" title="Edit section: Iterative method">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="thumb tright">
<div class="thumbinner" style="width:222px;"><a href="https://en.wikipedia.org/wiki/File:Stogra.png" class="image"><img alt="" src="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/220px-Stogra.png" width="220" height="173" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/en/thumb/f/f3/Stogra.png/330px-Stogra.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/f/f3/Stogra.png/440px-Stogra.png 2x" data-file-width="484" data-file-height="380"></a>
<div class="thumbcaption">
<div class="magnify"><a href="https://en.wikipedia.org/wiki/File:Stogra.png" class="internal" title="Enlarge"></a></div>
Fluctuations in the total objective function as gradient steps with respect to mini-batches are taken.</div>
</div>
</div>
<p>In stochastic (or "on-line") gradient descent, the true gradient of <img class="mwe-math-fallback-image-inline tex" alt="Q(w)" src="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/442953735b7d346fc2701b284c36ab58.png"> is approximated by a gradient at a single example:</p>
<dl>
<dd><img class="mwe-math-fallback-image-inline tex" alt="w := w - \eta \nabla Q_i(w)." src="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/5aefb6cbb99e3fc0862912efa8a3b54c.png"></dd>
</dl>
<p>As the algorithm sweeps through the training set, it performs the above update for each training example. Several passes can be made over the training set until the algorithm converges. If this is done, the data can be shuffled for each pass to prevent cycles. Typical implementations may use an adaptive learning rate so that the algorithm converges.</p>
<p>In pseudocode, stochastic gradient descent can be presented as follows:</p>
<div style="margin-left: 35px; width: 600px">
<div style="width:autoÂ ; margin-left: margin-bottom:1.25em;border:1px solid #8898BF; background:transparent;padding:0">
<div style="height:8px;margin:0;border:0;border-bottom:1px solid #8898BF;background: #C8D8FF;font-size:1px"></div>
<div style="padding:5px;font-size:small">
<ul>
<li>Choose an initial vector of parameters <img class="mwe-math-fallback-image-inline tex" alt="w" src="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/f1290186a5d0b1ceab27f4e77c0c5d68.png"> and learning rate <img class="mwe-math-fallback-image-inline tex" alt="\eta" src="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/7174cbd6aeaaa56e37102b72386bb2b9.png">.</li>
<li>Repeat until an approximate minimum is obtained:
<ul>
<li>Randomly shuffle examples in the training set.</li>
<li>For <img class="mwe-math-fallback-image-inline tex" alt="\! i=1, 2, ..., n" src="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/228ce9c975d39dd9ff6be17a1785e741.png">, do:
<ul>
<li><img class="mwe-math-fallback-image-inline tex" alt="\! w := w - \eta \nabla Q_i(w)." src="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/172b87a381467d11278b9defc36ea597.png"></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
<p>A compromise between the two forms called "mini-batches" computes the gradient against more than one training examples at each step. This can perform significantly better than true stochastic gradient descent because the code can make use of vectorization libraries rather than computing each step separately. It may also result in smoother convergence, as the gradient computed at each step uses more training examples.</p>
<p>The convergence of stochastic gradient descent has been analyzed using the theories of <a href="https://en.wikipedia.org/wiki/Convex_optimization" title="Convex optimization">convex minimization</a> and of <a href="https://en.wikipedia.org/wiki/Stochastic_approximation" title="Stochastic approximation">stochastic approximation</a>. Briefly, when the learning rates <img class="mwe-math-fallback-image-inline tex" alt="\eta" src="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/7174cbd6aeaaa56e37102b72386bb2b9.png"> decrease with an appropriate rate, and subject to relatively mild assumptions, stochastic gradient descent converges almost surely to a global minimum when the objective function is <a href="https://en.wikipedia.org/wiki/Convex_function" title="Convex function">convex</a> or <a href="https://en.wikipedia.org/wiki/Pseudoconvex_function" title="Pseudoconvex function">pseudoconvex</a>, and otherwise converges almost surely to a local minimum.<sup id="cite_ref-3" class="reference"><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#cite_note-3"><span>[</span>3<span>]</span></a></sup> <sup id="cite_ref-4" class="reference"><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#cite_note-4"><span>[</span>4<span>]</span></a></sup> This is in fact a consequence of the Robbins-Siegmund theorem.<sup id="cite_ref-5" class="reference"><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#cite_note-5"><span>[</span>5<span>]</span></a></sup></p>
<h2><span class="mw-headline" id="Example">Example</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Stochastic_gradient_descent&action=edit&section=3" title="Edit section: Example">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Let's suppose we want to fit a straight line <img class="mwe-math-fallback-image-inline tex" alt="y = \! w_1 + w_2 x" src="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/a1284d16583ba729e0276b3eeb51270a.png"> to a training set of two-dimensional points <img class="mwe-math-fallback-image-inline tex" alt="\! (x_1, y_1), \ldots, (x_n, y_n)" src="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/e9845e777d059e1b98524ac65519ac2a.png"> using <a href="https://en.wikipedia.org/wiki/Least_squares" title="Least squares">least squares</a>. The objective function to be minimized is:</p>
<dl>
<dd><img class="mwe-math-fallback-image-inline tex" alt="Q(w) = \sum_{i=1}^n Q_i(w) = \sum_{i=1}^n \left(w_1 + w_2 x_i - y_i\right)^2." src="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/d60ddf2d9e976bc03ed96186e24adc70.png"></dd>
</dl>
<p>The last line in the above pseudocode for this specific problem will become:</p>
<dl>
<dd><img class="mwe-math-fallback-image-inline tex" alt="\begin{bmatrix} w_1 \\ w_2 \end{bmatrix} :=
    \begin{bmatrix} w_1 \\ w_2 \end{bmatrix}
    -  \eta  \begin{bmatrix} 2 (w_1 + w_2 x_i - y_i) \\ 2 x_i(w_1 + w_2 x_i - y_i) \end{bmatrix}." src="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/180a59405206eb7ae33d37062345b01a.png"></dd>
</dl>
<h2><span class="mw-headline" id="Applications">Applications</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Stochastic_gradient_descent&action=edit&section=4" title="Edit section: Applications">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Stochastic gradient descent is a popular algorithm for training a wide range of models in <a href="https://en.wikipedia.org/wiki/Machine_learning" title="Machine learning">machine learning</a>, including (linear) <a href="https://en.wikipedia.org/wiki/Support_vector_machine" title="Support vector machine">support vector machines</a>, <a href="https://en.wikipedia.org/wiki/Logistic_regression" title="Logistic regression">logistic regression</a> (see, e.g., <a href="https://en.wikipedia.org/wiki/Vowpal_Wabbit" title="Vowpal Wabbit">Vowpal Wabbit</a>) and <a href="https://en.wikipedia.org/wiki/Graphical_model" title="Graphical model">graphical models</a>.<sup id="cite_ref-6" class="reference"><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#cite_note-6"><span>[</span>6<span>]</span></a></sup> When combined with the <a href="https://en.wikipedia.org/wiki/Backpropagation" title="Backpropagation">backpropagation</a> algorithm, it is the <i>de facto</i> standard algorithm for training <a href="https://en.wikipedia.org/wiki/Artificial_neural_network" title="Artificial neural network">artificial neural networks</a>.</p>
<p>SGD competes with the <a href="https://en.wikipedia.org/wiki/Limited-memory_BFGS" title="Limited-memory BFGS">L-BFGS</a> algorithm,<sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">[<i><a href="https://en.wikipedia.org/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (July 2015)">citation needed</span></a></i>]</sup> which is also widely used. SGD has been used since at least 1960 for training <a href="https://en.wikipedia.org/wiki/Linear_regression" title="Linear regression">linear regression</a> models, originally under the name <a href="https://en.wikipedia.org/wiki/ADALINE" title="ADALINE">ADALINE</a>.<sup id="cite_ref-7" class="reference"><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#cite_note-7"><span>[</span>7<span>]</span></a></sup></p>
<p>Another popular stochastic gradient descent algorithm is the <a href="https://en.wikipedia.org/wiki/Least_mean_squares_filter" title="Least mean squares filter">least mean squares (LMS)</a> adaptive filter.</p>
<h2><span class="mw-headline" id="Extensions_and_variants">Extensions and variants</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Stochastic_gradient_descent&action=edit&section=5" title="Edit section: Extensions and variants">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Many improvements on the basic SGD algorithm have been proposed and used. In particular, in machine learning, the need to set a learning rate (step size) has been recognized as problematic. Setting this parameter too high can cause the algorithm to diverge; setting it too low makes it slow to converge. A conceptually simple extension of SGD makes the learning rate a decreasing function <span class="texhtml mvar" style="font-style:italic;">Î·<sub>t</sub></span> of the iteration number <span class="texhtml mvar" style="font-style:italic;">t</span>, giving a <i>learning rate schedule</i>, so that the first iterations cause large changes in the parameters, while the later ones do only fine-tuning. Such schedules have been known since the work of MacQueen on <a href="https://en.wikipedia.org/wiki/K-means_clustering" title="K-means clustering"><span class="texhtml mvar" style="font-style:italic;">k</span>-means clustering</a>.<sup id="cite_ref-8" class="reference"><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#cite_note-8"><span>[</span>8<span>]</span></a></sup></p>
<h3><span class="mw-headline" id="Momentum">Momentum</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Stochastic_gradient_descent&action=edit&section=6" title="Edit section: Momentum">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Further proposals include the <i>momentum method</i>, which appeared in <a href="https://en.wikipedia.org/wiki/David_Rumelhart" title="David Rumelhart">Rumelhart</a>, <a href="https://en.wikipedia.org/wiki/Geoffrey_Hinton" title="Geoffrey Hinton">Hinton</a> and <a href="https://en.wikipedia.org/wiki/Ronald_J._Williams" title="Ronald J. Williams">Williams</a>' seminal paper on backpropagation learning.<sup id="cite_ref-Rumelhart1986_9-0" class="reference"><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#cite_note-Rumelhart1986-9"><span>[</span>9<span>]</span></a></sup> SGD with momentum remembers the update <span class="texhtml">Î <i>w</i></span> at each iteration, and determines the next update as a <a href="https://en.wikipedia.org/wiki/Convex_combination" title="Convex combination">convex combination</a> of the gradient and the previous update:</p>
<dl>
<dd><img class="mwe-math-fallback-image-inline tex" alt="\Delta w := \eta \nabla Q_i(w) + \alpha \Delta w" src="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/0db3f5a7ec4b7a5321ba1b8477a454dd.png"></dd>
<dd><img class="mwe-math-fallback-image-inline tex" alt="w := w - \eta \Delta w " src="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/fc41fb62a192cf6ca3bb4abbb9ed6d3d.png"></dd>
</dl>
<p>The name momentum stems from an analogy to <a href="https://en.wikipedia.org/wiki/Momentum" title="Momentum">momentum</a> in physics: the weight vector, thought of as a particle traveling through parameter space,<sup id="cite_ref-Rumelhart1986_9-1" class="reference"><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#cite_note-Rumelhart1986-9"><span>[</span>9<span>]</span></a></sup> incurs acceleration from the gradient of the loss ("<a href="https://en.wikipedia.org/wiki/Force" title="Force">force</a>"). Unlike in classical SGD, it tends to keep traveling in the same direction, preventing oscillations. Momentum has been used successfully for several decades.<sup id="cite_ref-Zeiler_2012_10-0" class="reference"><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#cite_note-Zeiler_2012-10"><span>[</span>10<span>]</span></a></sup></p>
<h3><span class="mw-headline" id="Averaging">Averaging</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Stochastic_gradient_descent&action=edit&section=7" title="Edit section: Averaging">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p><i>Averaged SGD</i>, invented independently by Ruppert and Polyak in the late 1980s, is ordinary SGD that records an average of its parameter vector over time. That is, the update is the same as for ordinary SGD, but the algorithm also keeps track of<sup id="cite_ref-11" class="reference"><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#cite_note-11"><span>[</span>11<span>]</span></a></sup></p>
<dl>
<dd><img class="mwe-math-fallback-image-inline tex" alt="\bar{w} = \frac{1}{t} \sum_{i=0}^{t-1} w_i" src="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/5e34915024328500f72ef2ea2d843075.png">.</dd>
</dl>
<p>When optimization is done, this averaged parameter vector takes the place of <span class="texhtml mvar" style="font-style:italic;">w</span>.</p>
<h3><span class="mw-headline" id="AdaGrad">AdaGrad</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Stochastic_gradient_descent&action=edit&section=8" title="Edit section: AdaGrad">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p><i>AdaGrad</i> (for adaptive <a href="https://en.wikipedia.org/wiki/Gradient_descent" title="Gradient descent">gradient</a> algorithm) is an enhanced SGD that automatically determines a per-parameter learning rate.<sup id="cite_ref-12" class="reference"><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#cite_note-12"><span>[</span>12<span>]</span></a></sup><sup id="cite_ref-13" class="reference"><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#cite_note-13"><span>[</span>13<span>]</span></a></sup> It still has a base learning rate <span class="texhtml mvar" style="font-style:italic;">Î·</span>, but this is multiplied with the elements of a vector <span class="texhtml">{<i>G</i><sub><i>j</i>,<i>j</i></sub>}</span> that is thought of as the diagonal of a matrix</p>
<dl>
<dd><img class="mwe-math-fallback-image-inline tex" alt="G = \sum_{\tau=1}^t g_\tau g_\tau^\mathsf{T}" src="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/e0747dff00037f8527cf278afe0d23bc.png"></dd>
</dl>
<p>where <img class="mwe-math-fallback-image-inline tex" alt="g_\tau = \nabla Q_i(w)" src="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/9a5e3295502aacaa9509ce45652e09d9.png">, the gradient, at iteration <span class="texhtml mvar" style="font-style:italic;">Ï</span>. The diagonal is given by</p>
<dl>
<dd><img class="mwe-math-fallback-image-inline tex" alt="G_{j,j} = \sum_{\tau=1}^t g_{\tau,j}^2" src="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/c27519a1a162f0431c5753ce53107281.png">.</dd>
</dl>
<p>This vector is updated after every iteration. The formula for an update is now</p>
<dl>
<dd><img class="mwe-math-fallback-image-inline tex" alt="w := w - \eta\, \mathrm{diag}(G)^{-\frac{1}{2}} \circ g" src="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/5c7c9cb9ad40ca7cce7d8d225b9c6bdc.png"><sup id="cite_ref-14" class="reference"><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#cite_note-14"><span>[</span>a<span>]</span></a></sup></dd>
</dl>
<p>or, written as per-parameter updates,</p>
<dl>
<dd><img class="mwe-math-fallback-image-inline tex" alt="w_j := w_j - \frac{\eta}\sqrt{G_{j,j}} g_j." src="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/fadba137bdf3a852f0d1b8406f929e44.png"></dd>
</dl>
<p>Each <span class="texhtml">{<i>G</i><sub>(<i>i</i>,<i>i</i>)</sub>}</span> gives rise to a scaling factor for the learning rate that applies to a single parameter <span class="texhtml"><i>w</i><sub><i>i</i></sub></span>. Since the denominator in this factor, <img class="mwe-math-fallback-image-inline tex" alt="\sqrt{G_i} = \sqrt{\sum_{\tau=1}^t g_\tau^2}" src="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/0eb2887be88c32a76ea6ec77dea7e4ae.png"> is the <a href="https://en.wikipedia.org/wiki/Norm_(mathematics)#Euclidean_norm" title="Norm (mathematics)"><i>â</i><sub>2</sub> norm</a> of previous derivatives, extreme parameter updates get dampened, while parameters that get few or small updates receive higher learning rates.<sup id="cite_ref-Zeiler_2012_10-1" class="reference"><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#cite_note-Zeiler_2012-10"><span>[</span>10<span>]</span></a></sup></p>
<p>While designed for <a href="https://en.wikipedia.org/wiki/Convex_optimization" title="Convex optimization">convex problems</a>, AdaGrad has been successfully applied to non-convex optimization.<sup id="cite_ref-15" class="reference"><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#cite_note-15"><span>[</span>14<span>]</span></a></sup></p>
<h2><span class="mw-headline" id="Notes">Notes</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Stochastic_gradient_descent&action=edit&section=9" title="Edit section: Notes">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="reflist" style="list-style-type: lower-alpha;">
<ol class="references">
<li id="cite_note-14"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#cite_ref-14"><span class="cite-accessibility-label">Jump up </span>^</a></b></span> <span class="reference-text"><img class="mwe-math-fallback-image-inline tex" alt="\circ" src="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/10c3e97d2a3eda0d182b81d48f231b62.png"> is the <a href="https://en.wikipedia.org/wiki/Hadamard_product_(matrices)" title="Hadamard product (matrices)">element-wise product</a>.</span></li>
</ol>
</div>
<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Stochastic_gradient_descent&action=edit&section=10" title="Edit section: See also">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Linear_classifier" title="Linear classifier">Linear classifier</a></li>
<li><a href="https://en.wikipedia.org/wiki/Online_machine_learning" title="Online machine learning">Online machine learning</a></li>
</ul>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Stochastic_gradient_descent&action=edit&section=11" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="reflist columns references-column-width" style="-moz-column-width: 30em; -webkit-column-width: 30em; column-width: 30em; list-style-type: decimal;">
<ol class="references">
<li id="cite_note-1"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#cite_ref-1"><span class="cite-accessibility-label">Jump up </span>^</a></b></span> <span class="reference-text"><span class="citation journal">Ferguson, Thomas S. (1982). "An inconsistent maximum likelihood estimate". <i>Journal of the American Statistical Association</i> <b>77</b> (380): 831â834. <a href="https://en.wikipedia.org/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://dx.doi.org/10.1080%2F01621459.1982.10477894">10.1080/01621459.1982.10477894</a>. <a href="https://en.wikipedia.org/wiki/JSTOR" title="JSTOR">JSTOR</a>&nbsp;<a rel="nofollow" class="external text" href="https://www.jstor.org/stable/2287314">2287314</a>.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+gradient+descent&amp;rft.atitle=An+inconsistent+maximum+likelihood+estimate&amp;rft.au=Ferguson%2C+Thomas+S.&amp;rft.aufirst=Thomas+S.&amp;rft.aulast=Ferguson&amp;rft.date=1982&amp;rft.genre=article&amp;rft_id=info%3Adoi%2F10.1080%2F01621459.1982.10477894&amp;rft.issue=380&amp;rft.jstor=2287314&amp;rft.jtitle=Journal+of+the+American+Statistical+Association&amp;rft.pages=831-834&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=77" class="Z3988"><span style="display:none;">&nbsp;</span></span></span></li>
<li id="cite_note-2"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#cite_ref-2"><span class="cite-accessibility-label">Jump up </span>^</a></b></span> <span class="reference-text"><span class="citation conference"><a href="https://en.wikipedia.org/wiki/L%C3%A9on_Bottou" title="LÃ©on Bottou">Bottou, LÃ©on</a>; Bousquet, Olivier (2008). <a rel="nofollow" class="external text" href="http://leon.bottou.org/papers/bottou-bousquet-2008"><i>The Tradeoffs of Large Scale Learning</i></a>. <a href="https://en.wikipedia.org/wiki/Advances_in_Neural_Information_Processing_Systems" title="Advances in Neural Information Processing Systems" class="mw-redirect">Advances in Neural Information Processing Systems</a> <b>20</b>. pp.&nbsp;161â168.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+gradient+descent&amp;rft.au=Bottou%2C+L%C3%A9on&amp;rft.au=Bousquet%2C+Olivier&amp;rft.aufirst=L%C3%A9on&amp;rft.aulast=Bottou&amp;rft.btitle=The+Tradeoffs+of+Large+Scale+Learning&amp;rft.date=2008&amp;rft.genre=book&amp;rft_id=http%3A%2F%2Fleon.bottou.org%2Fpapers%2Fbottou-bousquet-2008&amp;rft.pages=161-168&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.volume=20" class="Z3988"><span style="display:none;">&nbsp;</span></span></span></li>
<li id="cite_note-3"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#cite_ref-3"><span class="cite-accessibility-label">Jump up </span>^</a></b></span> <span class="reference-text"><span class="citation book"><a href="https://en.wikipedia.org/wiki/L%C3%A9on_Bottou" title="LÃ©on Bottou">Bottou, LÃ©on</a> (1998). "Online Algorithms and Stochastic Approximations". <a rel="nofollow" class="external text" href="http://leon.bottou.org/papers/bottou-98x"><i>Online Learning and Neural Networks</i></a>. Cambridge University Press. <a href="https://en.wikipedia.org/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-0-521-65263-6" title="Special:BookSources/978-0-521-65263-6">978-0-521-65263-6</a></span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+gradient+descent&amp;rft.atitle=Online+Algorithms+and+Stochastic+Approximations&amp;rft.au=Bottou%2C+L%C3%A9on&amp;rft.aufirst=L%C3%A9on&amp;rft.aulast=Bottou&amp;rft.btitle=Online+Learning+and+Neural+Networks&amp;rft.date=1998&amp;rft.genre=bookitem&amp;rft_id=http%3A%2F%2Fleon.bottou.org%2Fpapers%2Fbottou-98x&amp;rft.isbn=978-0-521-65263-6&amp;rft.pub=Cambridge+University+Press&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;">&nbsp;</span></span></span></li>
<li id="cite_note-4"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#cite_ref-4"><span class="cite-accessibility-label">Jump up </span>^</a></b></span> <span class="reference-text"><span class="citation news">Kiwiel, Krzysztof C. (2001). "Convergence and efficiency of subgradient methods for quasiconvex minimization". <i>Mathematical Programming (Series A)</i> <b>90</b> (1) (Berlin, Heidelberg: Springer). pp.&nbsp;1â25. <a href="https://en.wikipedia.org/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://dx.doi.org/10.1007%2FPL00011414">10.1007/PL00011414</a>. <a href="https://en.wikipedia.org/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&nbsp;<a rel="nofollow" class="external text" href="https://www.worldcat.org/issn/0025-5610">0025-5610</a>. <a href="https://en.wikipedia.org/wiki/Mathematical_Reviews" title="Mathematical Reviews">MR</a>&nbsp;<a rel="nofollow" class="external text" href="https://www.ams.org/mathscinet-getitem?mr=1819784">1819784</a>.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+gradient+descent&amp;rft.atitle=Convergence+and+efficiency+of+subgradient+methods+for+quasiconvex+minimization&amp;rft.aufirst=Krzysztof+C.&amp;rft.au=Kiwiel%2C+Krzysztof+C.&amp;rft.aulast=Kiwiel&amp;rft.date=2001&amp;rft.genre=article&amp;rft_id=info%3Adoi%2F10.1007%2FPL00011414&amp;rft.issn=0025-5610&amp;rft.issue=1&amp;rft.jtitle=Mathematical+Programming++%28Series+A%29&amp;rft.mr=1819784&amp;rft.pages=1-25&amp;rft.place=Berlin%2C+Heidelberg&amp;rft.pub=Springer&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=90" class="Z3988"><span style="display:none;">&nbsp;</span></span></span></li>
<li id="cite_note-5"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#cite_ref-5"><span class="cite-accessibility-label">Jump up </span>^</a></b></span> <span class="reference-text"><span class="citation book"><a href="https://en.wikipedia.org/wiki/Herbert_Robbins" title="Herbert Robbins">Robbins, Herbert</a>; <a href="https://en.wikipedia.org/wiki/David_O._Siegmund" title="David O. Siegmund" class="mw-redirect">Siegmund, David O.</a> (1971). "A convergence theorem for non negative almost supermartingales and some applications". In Rustagi, Jagdish S. <i>Optimizing Methods in Statistics</i>. Academic Press</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+gradient+descent&amp;rft.atitle=A+convergence+theorem+for+non+negative+almost+supermartingales+and+some+applications&amp;rft.aufirst=Herbert&amp;rft.aulast=Robbins&amp;rft.au=Robbins%2C+Herbert&amp;rft.au=Siegmund%2C+David+O.&amp;rft.btitle=Optimizing+Methods+in+Statistics&amp;rft.date=1971&amp;rft.genre=bookitem&amp;rft.pub=Academic+Press&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;">&nbsp;</span></span></span></li>
<li id="cite_note-6"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#cite_ref-6"><span class="cite-accessibility-label">Jump up </span>^</a></b></span> <span class="reference-text">Jenny Rose Finkel, Alex Kleeman, Christopher D. Manning (2008). Efficient, Feature-based, Conditional Random Field Parsing. Proc. Annual Meeting of the ACL.</span></li>
<li id="cite_note-7"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#cite_ref-7"><span class="cite-accessibility-label">Jump up </span>^</a></b></span> <span class="reference-text"><span class="citation web">Avi Pfeffer. <a rel="nofollow" class="external text" href="http://www.seas.harvard.edu/courses/cs181/files/lecture05-notes.pdf">"CS181 Lecture 5 â Perceptrons"</a> <span style="font-size:85%;">(PDF)</span>. Harvard University.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+gradient+descent&amp;rft.au=Avi+Pfeffer&amp;rft.aulast=Avi+Pfeffer&amp;rft.btitle=CS181+Lecture+5+%E2%80%94+Perceptrons&amp;rft.genre=book&amp;rft_id=http%3A%2F%2Fwww.seas.harvard.edu%2Fcourses%2Fcs181%2Ffiles%2Flecture05-notes.pdf&amp;rft.pub=Harvard+University&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;">&nbsp;</span></span></span></li>
<li id="cite_note-8"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#cite_ref-8"><span class="cite-accessibility-label">Jump up </span>^</a></b></span> <span class="reference-text">Cited by <span class="citation conference">Darken, Christian; Moody, John (1990). <i>Fast adaptive k-means clustering: some empirical results</i>. Int'l Joint Conf. on Neural Networks (IJCNN). IEEE.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+gradient+descent&amp;rft.au=Darken%2C+Christian&amp;rft.aufirst=Christian&amp;rft.aulast=Darken&amp;rft.au=Moody%2C+John&amp;rft.btitle=Fast+adaptive+k-means+clustering%3A+some+empirical+results&amp;rft.date=1990&amp;rft.genre=book&amp;rft.pub=IEEE&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;">&nbsp;</span></span></span></li>
<li id="cite_note-Rumelhart1986-9"><span class="mw-cite-backlink">^ <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#cite_ref-Rumelhart1986_9-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#cite_ref-Rumelhart1986_9-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><span class="citation journal">Rumelhart, David E.; Hinton, Geoffrey E.; Williams, Ronald J. (8 October 1986). "Learning representations by back-propagating errors". <i>Nature</i> <b>323</b> (6088): 533â536. <a href="https://en.wikipedia.org/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://dx.doi.org/10.1038%2F323533a0">10.1038/323533a0</a>.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+gradient+descent&amp;rft.atitle=Learning+representations+by+back-propagating+errors&amp;rft.aufirst=David+E.&amp;rft.au=Hinton%2C+Geoffrey+E.&amp;rft.aulast=Rumelhart&amp;rft.au=Rumelhart%2C+David+E.&amp;rft.au=Williams%2C+Ronald+J.&amp;rft.date=8+October+1986&amp;rft.genre=article&amp;rft_id=info%3Adoi%2F10.1038%2F323533a0&amp;rft.issue=6088&amp;rft.jtitle=Nature&amp;rft.pages=533-536&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=323" class="Z3988"><span style="display:none;">&nbsp;</span></span></span></li>
<li id="cite_note-Zeiler_2012-10"><span class="mw-cite-backlink">^ <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#cite_ref-Zeiler_2012_10-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#cite_ref-Zeiler_2012_10-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><span class="citation arxiv">Zeiler, Matthew D. (2012). "ADADELTA: An adaptive learning rate method". <a href="https://en.wikipedia.org/wiki/ArXiv" title="ArXiv">arXiv</a>:<a rel="nofollow" class="external text" href="https://arxiv.org/abs/1212.5701">1212.5701</a>.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+gradient+descent&amp;rft.atitle=ADADELTA%3A+An+adaptive+learning+rate+method&amp;rft.aufirst=Matthew+D.&amp;rft.aulast=Zeiler&amp;rft.au=Zeiler%2C+Matthew+D.&amp;rft.date=2012&amp;rft.genre=preprint&amp;rft_id=info%3Aarxiv%2F1212.5701&amp;rft.jtitle=arXiv&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal" class="Z3988"><span style="display:none;">&nbsp;</span></span></span></li>
<li id="cite_note-11"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#cite_ref-11"><span class="cite-accessibility-label">Jump up </span>^</a></b></span> <span class="reference-text"><span class="citation journal">Polyak, Boris T.; Juditsky, Anatoli B. (1992). "Acceleration of stochastic approximation by averaging". <i>SIAM J. Control and Optimization</i> <b>30</b> (4): 838â855.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+gradient+descent&amp;rft.atitle=Acceleration+of+stochastic+approximation+by+averaging&amp;rft.aufirst=Boris+T.&amp;rft.au=Juditsky%2C+Anatoli+B.&amp;rft.aulast=Polyak&amp;rft.au=Polyak%2C+Boris+T.&amp;rft.date=1992&amp;rft.genre=article&amp;rft.issue=4&amp;rft.jtitle=SIAM+J.+Control+and+Optimization&amp;rft.pages=838-855&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=30" class="Z3988"><span style="display:none;">&nbsp;</span></span></span></li>
<li id="cite_note-12"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#cite_ref-12"><span class="cite-accessibility-label">Jump up </span>^</a></b></span> <span class="reference-text"><span class="citation journal">Duchi, John; Hazan, Elad; Singer, Yoram (2011). <a rel="nofollow" class="external text" href="http://jmlr.org/papers/volume12/duchi11a/duchi11a.pdf">"Adaptive subgradient methods for online learning and stochastic optimization"</a> <span style="font-size:85%;">(PDF)</span>. <i><a href="https://en.wikipedia.org/wiki/Journal_of_Machine_Learning_Research" title="Journal of Machine Learning Research">JMLR</a></i> <b>12</b>: 2121â2159.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+gradient+descent&amp;rft.atitle=Adaptive+subgradient+methods+for+online+learning+and+stochastic+optimization&amp;rft.au=Duchi%2C+John&amp;rft.aufirst=John&amp;rft.au=Hazan%2C+Elad&amp;rft.aulast=Duchi&amp;rft.au=Singer%2C+Yoram&amp;rft.date=2011&amp;rft.genre=article&amp;rft_id=http%3A%2F%2Fjmlr.org%2Fpapers%2Fvolume12%2Fduchi11a%2Fduchi11a.pdf&amp;rft.jtitle=JMLR&amp;rft.pages=2121-2159&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=12" class="Z3988"><span style="display:none;">&nbsp;</span></span></span></li>
<li id="cite_note-13"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#cite_ref-13"><span class="cite-accessibility-label">Jump up </span>^</a></b></span> <span class="reference-text"><span class="citation web">Perla, Joseph (2014). <a rel="nofollow" class="external text" href="http://seed.ucsd.edu/mediawiki/images/6/6a/Adagrad.pdf">"Notes on AdaGrad"</a> <span style="font-size:85%;">(PDF)</span>.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+gradient+descent&amp;rft.aufirst=Joseph&amp;rft.aulast=Perla&amp;rft.au=Perla%2C+Joseph&amp;rft.btitle=Notes+on+AdaGrad&amp;rft.date=2014&amp;rft.genre=book&amp;rft_id=http%3A%2F%2Fseed.ucsd.edu%2Fmediawiki%2Fimages%2F6%2F6a%2FAdagrad.pdf&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;">&nbsp;</span></span></span></li>
<li id="cite_note-15"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#cite_ref-15"><span class="cite-accessibility-label">Jump up </span>^</a></b></span> <span class="reference-text"><span class="citation journal">Gupta, Maya R.; Bengio, Samy; Weston, Jason (2014). <a rel="nofollow" class="external text" href="http://jmlr.org/papers/volume15/gupta14a/gupta14a.pdf">"Training highly multiclass classifiers"</a> <span style="font-size:85%;">(PDF)</span>. <i>JMLR</i> <b>15</b> (1): 1461â1492.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+gradient+descent&amp;rft.atitle=Training+highly+multiclass+classifiers&amp;rft.au=Bengio%2C+Samy&amp;rft.aufirst=Maya+R.&amp;rft.au=Gupta%2C+Maya+R.&amp;rft.aulast=Gupta&amp;rft.au=Weston%2C+Jason&amp;rft.date=2014&amp;rft.genre=article&amp;rft_id=http%3A%2F%2Fjmlr.org%2Fpapers%2Fvolume15%2Fgupta14a%2Fgupta14a.pdf&amp;rft.issue=1&amp;rft.jtitle=JMLR&amp;rft.pages=1461-1492&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=15" class="Z3988"><span style="display:none;">&nbsp;</span></span></span></li>
</ol>
</div>
<h2><span class="mw-headline" id="Further_reading">Further reading</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Stochastic_gradient_descent&action=edit&section=12" title="Edit section: Further reading">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul>
<li><span id="CITEREFBertsekas1999" class="citation"><a href="https://en.wikipedia.org/wiki/Dimitri_P._Bertsekas" title="Dimitri P. Bertsekas" class="mw-redirect">Bertsekas, Dimitri P.</a> (1999), <i>Nonlinear Programming</i> (2nd ed.), Cambridge, MA.: Athena Scientific, <a href="https://en.wikipedia.org/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/1-886529-00-0" title="Special:BookSources/1-886529-00-0">1-886529-00-0</a></span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+gradient+descent&amp;rft.au=Bertsekas%2C+Dimitri+P.&amp;rft.aufirst=Dimitri+P.&amp;rft.aulast=Bertsekas&amp;rft.btitle=Nonlinear+Programming&amp;rft.date=1999&amp;rft.edition=2nd&amp;rft.genre=book&amp;rft.isbn=1-886529-00-0&amp;rft.place=Cambridge%2C+MA.&amp;rft.pub=Athena+Scientific&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;">&nbsp;</span></span>.</li>
</ul>
<ul>
<li><span id="CITEREFBertsekas2003" class="citation"><a href="https://en.wikipedia.org/wiki/Dimitri_P._Bertsekas" title="Dimitri P. Bertsekas" class="mw-redirect">Bertsekas, Dimitri</a> (2003), <i>Convex Analysis and Optimization</i>, Athena Scientific</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+gradient+descent&amp;rft.au=Bertsekas%2C+Dimitri&amp;rft.aufirst=Dimitri&amp;rft.aulast=Bertsekas&amp;rft.btitle=Convex+Analysis+and+Optimization&amp;rft.date=2003&amp;rft.genre=book&amp;rft.pub=Athena+Scientific&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;">&nbsp;</span></span>.</li>
</ul>
<ul>
<li><span id="CITEREFBottou2004" class="citation"><a href="https://en.wikipedia.org/wiki/L%C3%A9on_Bottou" title="LÃ©on Bottou">Bottou, LÃ©on</a> (2004), "Stochastic Learning", <a rel="nofollow" class="external text" href="http://leon.bottou.org/papers/bottou-mlss-2004"><i>Advanced Lectures on Machine Learning</i></a>, LNAI <b>3176</b>, Springer, pp.&nbsp;146â168, <a href="https://en.wikipedia.org/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-3-540-23122-6" title="Special:BookSources/978-3-540-23122-6">978-3-540-23122-6</a></span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+gradient+descent&amp;rft.atitle=Stochastic+Learning&amp;rft.au=Bottou%2C+L%C3%A9on&amp;rft.aufirst=L%C3%A9on&amp;rft.aulast=Bottou&amp;rft.btitle=Advanced+Lectures+on+Machine+Learning&amp;rft.date=2004&amp;rft.genre=bookitem&amp;rft_id=http%3A%2F%2Fleon.bottou.org%2Fpapers%2Fbottou-mlss-2004&amp;rft.isbn=978-3-540-23122-6&amp;rft.pages=146-168&amp;rft.pub=Springer&amp;rft.series=LNAI&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.volume=3176" class="Z3988"><span style="display:none;">&nbsp;</span></span>.</li>
</ul>
<ul>
<li><span id="CITEREFDavidon1976" class="citation"><a href="https://en.wikipedia.org/wiki/William_C._Davidon" title="William C. Davidon">Davidon, W.C.</a> (1976), "New least-square algorithms", <i>Journal of Optimization Theory and Applications</i> <b>18</b> (2): 187â197, <a href="https://en.wikipedia.org/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://dx.doi.org/10.1007%2FBF00935703">10.1007/BF00935703</a>, <a href="https://en.wikipedia.org/wiki/Mathematical_Reviews" title="Mathematical Reviews">MR</a>&nbsp;<a rel="nofollow" class="external text" href="https://www.ams.org/mathscinet-getitem?mr=418461">418461</a></span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+gradient+descent&amp;rft.atitle=New+least-square+algorithms&amp;rft.au=Davidon%2C+W.C.&amp;rft.aufirst=W.C.&amp;rft.aulast=Davidon&amp;rft.date=1976&amp;rft.genre=article&amp;rft_id=info%3Adoi%2F10.1007%2FBF00935703&amp;rft.issue=2&amp;rft.jtitle=Journal+of+Optimization+Theory+and+Applications&amp;rft.mr=418461&amp;rft.pages=187-197&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=18" class="Z3988"><span style="display:none;">&nbsp;</span></span>.</li>
</ul>
<ul>
<li><span id="CITEREFDudaHartStork2000" class="citation">Duda, Richard O.; Hart, Peter E.; Stork, David G. (2000), <i>Pattern Classification</i> (2nd ed.), <a href="https://en.wikipedia.org/wiki/John_Wiley_%26_Sons" title="John Wiley &amp; Sons">Wiley</a>, <a href="https://en.wikipedia.org/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-0-471-05669-0" title="Special:BookSources/978-0-471-05669-0">978-0-471-05669-0</a></span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+gradient+descent&amp;rft.au=Duda%2C+Richard+O.&amp;rft.aufirst=Richard+O.&amp;rft.au=Hart%2C+Peter+E.&amp;rft.aulast=Duda&amp;rft.au=Stork%2C+David+G.&amp;rft.btitle=Pattern+Classification&amp;rft.date=2000&amp;rft.edition=2nd&amp;rft.genre=book&amp;rft.isbn=978-0-471-05669-0&amp;rft.pub=Wiley&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;">&nbsp;</span></span>.</li>
</ul>
<ul>
<li><span id="CITEREFKiwiel2004" class="citation">Kiwiel, Krzysztof C. (2004), "Convergence of approximate and incremental subgradient methods for convex optimization", <i>SIAM Journal of Optimization</i> <b>14</b> (3): 807â840, <a href="https://en.wikipedia.org/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://dx.doi.org/10.1137%2FS1052623400376366">10.1137/S1052623400376366</a>, <a href="https://en.wikipedia.org/wiki/Mathematical_Reviews" title="Mathematical Reviews">MR</a>&nbsp;<a rel="nofollow" class="external text" href="https://www.ams.org/mathscinet-getitem?mr=2085944">2085944</a></span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+gradient+descent&amp;rft.atitle=Convergence+of+approximate+and+incremental+subgradient+methods+for+convex+optimization&amp;rft.aufirst=Krzysztof+C.&amp;rft.au=Kiwiel%2C+Krzysztof+C.&amp;rft.aulast=Kiwiel&amp;rft.date=2004&amp;rft.genre=article&amp;rft_id=info%3Adoi%2F10.1137%2FS1052623400376366&amp;rft.issue=3&amp;rft.jtitle=SIAM+Journal+of+Optimization&amp;rft.mr=2085944&amp;rft.pages=807-840&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=14" class="Z3988"><span style="display:none;">&nbsp;</span></span>. (Extensive list of references)</li>
</ul>
<ul>
<li><span id="CITEREFSpall2003" class="citation">Spall, James C. (2003), <i>Introduction to Stochastic Search and Optimization</i>, <a href="https://en.wikipedia.org/wiki/John_Wiley_%26_Sons" title="John Wiley &amp; Sons">Wiley</a>, <a href="https://en.wikipedia.org/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-0-471-33052-3" title="Special:BookSources/978-0-471-33052-3">978-0-471-33052-3</a></span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+gradient+descent&amp;rft.aufirst=James+C.&amp;rft.aulast=Spall&amp;rft.au=Spall%2C+James+C.&amp;rft.btitle=Introduction+to+Stochastic+Search+and+Optimization&amp;rft.date=2003&amp;rft.genre=book&amp;rft.isbn=978-0-471-33052-3&amp;rft.pub=Wiley&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;">&nbsp;</span></span>.</li>
</ul>
<h2><span class="mw-headline" id="Software">Software</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Stochastic_gradient_descent&action=edit&section=13" title="Edit section: Software">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul>
<li><a rel="nofollow" class="external text" href="http://leon.bottou.org/projects/sgd">sgd</a>: an LGPL C++ library which uses stochastic gradient descent to fit <a href="https://en.wikipedia.org/wiki/Support_vector_machine" title="Support vector machine">SVM</a> and <a href="https://en.wikipedia.org/wiki/Conditional_random_field" title="Conditional random field">conditional random field</a> models.</li>
<li><a rel="nofollow" class="external text" href="http://klcl.pku.edu.cn/member/sunxu/code.htm">CRF-ADF</a> A <a href="https://en.wikipedia.org/wiki/C_Sharp_(programming_language)" title="C Sharp (programming language)">C#</a> toolkit of stochastic gradient descent and its feature-frequency-adaptive variation for training <a href="https://en.wikipedia.org/wiki/Conditional_random_field" title="Conditional random field">conditional random field</a> models.</li>
<li><a href="https://en.wikipedia.org/wiki/Vowpal_Wabbit" title="Vowpal Wabbit">Vowpal Wabbit</a>: BSD licence, fast scalable learning by John Langford and others. Includes several stochastic gradient descent variants. <a rel="nofollow" class="external text" href="https://github.com/JohnLangford/vowpal_wabbit">Source repository on github</a></li>
</ul>
<h2><span class="mw-headline" id="External_links">External links</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Stochastic_gradient_descent&action=edit&section=14" title="Edit section: External links">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul>
<li><a rel="nofollow" class="external text" href="http://codingplayground.blogspot.it/2013/05/stocastic-gradient-descent.html">Using stochastic gradient descent in C++, Boost, Ublas for linear regression</a></li>
</ul>


<!-- 
NewPP limit report
Parsed by mw1016
Cached time: 20150831113217
Cache expiry: 2592000
Dyanmic content: false
CPU time usage: 0.451 seconds
Real time usage: 2.261 seconds
Preprocessor visited node count: 1672/1000000
Preprocessor generated node count: 0/1500000
Postâexpand include size: 41721/2097152 bytes
Template argument size: 812/2097152 bytes
Highest expansion depth: 11/40
Expensive parser function count: 1/500
Lua time usage: 0.132/10.000 seconds
Lua memory usage: 3.75 MB/50 MB
Number of Wikibase entities loaded: 0-->

<!-- 
Transclusion expansion time report (%,ms,calls,template)
100.00% 2159.284      1 - -total
  7.99%  172.469      2 - Template:Reflist
  2.78%   59.980      5 - Template:Cite_journal
  2.20%   47.489      1 - Template:Citation_needed
  2.05%   44.233      7 - Template:Citation
  1.86%   40.070      1 - Template:Fix
  1.66%   35.845      2 - Template:Category_handler
  1.61%   34.802      1 - Template:Main
  1.28%   27.566      1 - Template:Efn
  0.80%   17.310      2 - Template:Cite_book
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:1180641-0!*!0!!en!4!*!math=0 and timestamp 20150831113215 and revision id 674349666
 -->
<noscript>&lt;img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" /&gt;</noscript></div>					<div class="printfooter">
						Retrieved from "<a dir="ltr" href="https://en.wikipedia.org/w/index.php?title=Stochastic_gradient_descent&oldid=674349666">https://en.wikipedia.org/w/index.php?title=Stochastic_gradient_descent&amp;oldid=674349666</a>"					</div>
				<div id="catlinks" class="catlinks"><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="https://en.wikipedia.org/wiki/Help:Category" title="Help:Category">Categories</a>: <ul><li><a href="https://en.wikipedia.org/wiki/Category:Stochastic_optimization" title="Category:Stochastic optimization">Stochastic optimization</a></li><li><a href="https://en.wikipedia.org/wiki/Category:Computational_statistics" title="Category:Computational statistics">Computational statistics</a></li><li><a href="https://en.wikipedia.org/wiki/Category:M-estimators" title="Category:M-estimators">M-estimators</a></li><li><a href="https://en.wikipedia.org/wiki/Category:Machine_learning_algorithms" title="Category:Machine learning algorithms">Machine learning algorithms</a></li><li><a href="https://en.wikipedia.org/wiki/Category:Convex_optimization" title="Category:Convex optimization">Convex optimization</a></li></ul></div><div id="mw-hidden-catlinks" class="mw-hidden-catlinks mw-hidden-cats-hidden">Hidden categories: <ul><li><a href="https://en.wikipedia.org/wiki/Category:Articles_with_inconsistent_citation_formats" title="Category:Articles with inconsistent citation formats">Articles with inconsistent citation formats</a></li><li><a href="https://en.wikipedia.org/wiki/Category:All_articles_with_unsourced_statements" title="Category:All articles with unsourced statements">All articles with unsourced statements</a></li><li><a href="https://en.wikipedia.org/wiki/Category:Articles_with_unsourced_statements_from_July_2015" title="Category:Articles with unsourced statements from July 2015">Articles with unsourced statements from July 2015</a></li></ul></div></div>				<div class="visualClear"></div>
							</div>
		</div>
		<div id="mw-navigation">
			<h2>Navigation menu</h2>

			<div id="mw-head">
									<div id="p-personal" role="navigation" class="" aria-labelledby="p-personal-label">
						<h3 id="p-personal-label">Personal tools</h3>
						<ul>
							<li id="pt-createaccount"><a href="https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Stochastic+gradient+descent&type=signup" title="You are encouraged to create an account and log in; however, it is not mandatory">Create account</a></li><li id="pt-login"><a href="https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Stochastic+gradient+descent" title="You&#39;re encouraged to log in; however, it&#39;s not mandatory. [ctrl-option-o]" accesskey="o">Log in</a></li>						</ul>
					</div>
									<div id="left-navigation">
										<div id="p-namespaces" role="navigation" class="vectorTabs" aria-labelledby="p-namespaces-label">
						<h3 id="p-namespaces-label">Namespaces</h3>
						<ul>
															<li id="ca-nstab-main" class="selected"><span><a href="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/Stochastic gradient descent - Wikipedia, the free encyclopedia.html" title="View the content page [ctrl-option-c]" accesskey="c">Article</a></span></li>
															<li id="ca-talk"><span><a href="https://en.wikipedia.org/wiki/Talk:Stochastic_gradient_descent" title="Discussion about the content page [ctrl-option-t]" accesskey="t" rel="discussion">Talk</a></span></li>
													</ul>
					</div>
										<div id="p-variants" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-variants-label">
												<h3 id="p-variants-label" tabindex="0">
							<span>Variants</span><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#" tabindex="-1"></a>
						</h3>

						<div class="menu">
							<ul>
															</ul>
						</div>
					</div>
									</div>
				<div id="right-navigation">
										<div id="p-views" role="navigation" class="vectorTabs" aria-labelledby="p-views-label">
						<h3 id="p-views-label">Views</h3>
						<ul>
															<li id="ca-view" class="selected"><span><a href="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/Stochastic gradient descent - Wikipedia, the free encyclopedia.html">Read</a></span></li>
															<li id="ca-edit"><span><a href="https://en.wikipedia.org/w/index.php?title=Stochastic_gradient_descent&action=edit" title="Edit this page [ctrl-option-e]" accesskey="e">Edit</a></span></li>
															<li id="ca-history" class="collapsible"><span><a href="https://en.wikipedia.org/w/index.php?title=Stochastic_gradient_descent&action=history" title="Past revisions of this page [ctrl-option-h]" accesskey="h">View history</a></span></li>
													</ul>
					</div>
										<div id="p-cactions" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-cactions-label">
						<h3 id="p-cactions-label" tabindex="0"><span>More</span><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#" tabindex="-1"></a></h3>

						<div class="menu">
							<ul>
															</ul>
						</div>
					</div>
										<div id="p-search" role="search">
						<h3>
							<label for="searchInput">Search</label>
						</h3>

						<form action="https://en.wikipedia.org/w/index.php" id="searchform">
							<div id="simpleSearch">
							<input type="search" name="search" placeholder="Search" title="Search Wikipedia [ctrl-option-f]" accesskey="f" id="searchInput" tabindex="1" autocomplete="off"><input type="hidden" value="Special:Search" name="title"><input type="submit" name="go" value="Go" title="Go to a page with this exact name if it exists" id="searchButton" class="searchButton">							</div>
						</form>
					</div>
									</div>
			</div>
			<div id="mw-panel">
				<div id="p-logo" role="banner"><a class="mw-wiki-logo" href="https://en.wikipedia.org/wiki/Main_Page" title="Visit the main page"></a></div>
						<div class="portal" role="navigation" id="p-navigation" aria-labelledby="p-navigation-label">
			<h3 id="p-navigation-label">Navigation</h3>

			<div class="body">
									<ul>
						<li id="n-mainpage-description"><a href="https://en.wikipedia.org/wiki/Main_Page" title="Visit the main page [ctrl-option-z]" accesskey="z">Main page</a></li><li id="n-contents"><a href="https://en.wikipedia.org/wiki/Portal:Contents" title="Guides to browsing Wikipedia">Contents</a></li><li id="n-featuredcontent"><a href="https://en.wikipedia.org/wiki/Portal:Featured_content" title="Featured content â the best of Wikipedia">Featured content</a></li><li id="n-currentevents"><a href="https://en.wikipedia.org/wiki/Portal:Current_events" title="Find background information on current events">Current events</a></li><li id="n-randompage"><a href="https://en.wikipedia.org/wiki/Special:Random" title="Load a random article [ctrl-option-x]" accesskey="x">Random article</a></li><li id="n-sitesupport"><a href="https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&utm_medium=sidebar&utm_campaign=C13_en.wikipedia.org&uselang=en" title="Support us">Donate to Wikipedia</a></li><li id="n-shoplink"><a href="https://shop.wikimedia.org/" title="Visit the Wikipedia store">Wikipedia store</a></li>					</ul>
							</div>
		</div>
			<div class="portal" role="navigation" id="p-interaction" aria-labelledby="p-interaction-label">
			<h3 id="p-interaction-label">Interaction</h3>

			<div class="body">
									<ul>
						<li id="n-help"><a href="https://en.wikipedia.org/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li><li id="n-aboutsite"><a href="https://en.wikipedia.org/wiki/Wikipedia:About" title="Find out about Wikipedia">About Wikipedia</a></li><li id="n-portal"><a href="https://en.wikipedia.org/wiki/Wikipedia:Community_portal" title="About the project, what you can do, where to find things">Community portal</a></li><li id="n-recentchanges"><a href="https://en.wikipedia.org/wiki/Special:RecentChanges" title="A list of recent changes in the wiki [ctrl-option-r]" accesskey="r">Recent changes</a></li><li id="n-contactpage"><a href="https://en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact page</a></li>					</ul>
							</div>
		</div>
			<div class="portal" role="navigation" id="p-tb" aria-labelledby="p-tb-label">
			<h3 id="p-tb-label">Tools</h3>

			<div class="body">
									<ul>
						<li id="t-whatlinkshere"><a href="https://en.wikipedia.org/wiki/Special:WhatLinksHere/Stochastic_gradient_descent" title="List of all English Wikipedia pages containing links to this page [ctrl-option-j]" accesskey="j">What links here</a></li><li id="t-recentchangeslinked"><a href="https://en.wikipedia.org/wiki/Special:RecentChangesLinked/Stochastic_gradient_descent" title="Recent changes in pages linked from this page [ctrl-option-k]" accesskey="k">Related changes</a></li><li id="t-upload"><a href="https://en.wikipedia.org/wiki/Wikipedia:File_Upload_Wizard" title="Upload files [ctrl-option-u]" accesskey="u">Upload file</a></li><li id="t-specialpages"><a href="https://en.wikipedia.org/wiki/Special:SpecialPages" title="A list of all special pages [ctrl-option-q]" accesskey="q">Special pages</a></li><li id="t-permalink"><a href="https://en.wikipedia.org/w/index.php?title=Stochastic_gradient_descent&oldid=674349666" title="Permanent link to this revision of the page">Permanent link</a></li><li id="t-info"><a href="https://en.wikipedia.org/w/index.php?title=Stochastic_gradient_descent&action=info" title="More information about this page">Page information</a></li><li id="t-wikibase"><a href="https://www.wikidata.org/wiki/Q7617819" title="Link to connected data repository item [ctrl-option-g]" accesskey="g">Wikidata item</a></li><li id="t-cite"><a href="https://en.wikipedia.org/w/index.php?title=Special:CiteThisPage&page=Stochastic_gradient_descent&id=674349666" title="Information on how to cite this page">Cite this page</a></li>					</ul>
							</div>
		</div>
			<div class="portal" role="navigation" id="p-coll-print_export" aria-labelledby="p-coll-print_export-label">
			<h3 id="p-coll-print_export-label">Print/export</h3>

			<div class="body">
									<ul>
						<li id="coll-create_a_book"><a href="https://en.wikipedia.org/w/index.php?title=Special:Book&bookcmd=book_creator&referer=Stochastic+gradient+descent">Create a book</a></li><li id="coll-download-as-rdf2latex"><a href="https://en.wikipedia.org/w/index.php?title=Special:Book&bookcmd=render_article&arttitle=Stochastic+gradient+descent&oldid=674349666&writer=rdf2latex">Download as PDF</a></li><li id="t-print"><a href="https://en.wikipedia.org/w/index.php?title=Stochastic_gradient_descent&printable=yes" title="Printable version of this page [ctrl-option-p]" accesskey="p">Printable version</a></li>					</ul>
							</div>
		</div>
			<div class="portal" role="navigation" id="p-lang" aria-labelledby="p-lang-label"><span class="uls-settings-trigger" tabindex="0" role="button" aria-haspopup="true" original-title="Language settings"></span>
			<h3 id="p-lang-label">Languages</h3>

			<div class="body">
									<ul>
						<li class="interlanguage-link interwiki-fr"><a href="https://fr.wikipedia.org/wiki/Algorithme_du_gradient_stochastique" title="Algorithme du gradient stochastique â French" lang="fr" hreflang="fr">FranÃ§ais</a></li>					</ul>
				<div class="after-portlet after-portlet-lang"><span class="wb-langlinks-edit wb-langlinks-link"><a href="https://www.wikidata.org/wiki/Q7617819#sitelinks-wikipedia" title="Edit interlanguage links" class="wbc-editpage">Edit links</a></span></div>			</div>
		</div>
				</div>
		</div>
		<div id="footer" role="contentinfo">
							<ul id="footer-info">
											<li id="footer-info-lastmod"> This page was last modified on 3 August 2015, at 10:40.</li>
											<li id="footer-info-copyright">Text is available under the <a rel="license" href="https://en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License">Creative Commons Attribution-ShareAlike License</a><a rel="license" href="https://creativecommons.org/licenses/by-sa/3.0/" style="display:none;"></a>;
additional terms may apply.  By using this site, you agree to the <a href="https://wikimediafoundation.org/wiki/Terms_of_Use">Terms of Use</a> and <a href="https://wikimediafoundation.org/wiki/Privacy_policy">Privacy Policy</a>. WikipediaÂ® is a registered trademark of the <a href="https://www.wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>
									</ul>
							<ul id="footer-places">
											<li id="footer-places-privacy"><a href="https://wikimediafoundation.org/wiki/Privacy_policy" title="wikimedia:Privacy policy">Privacy policy</a></li>
											<li id="footer-places-about"><a href="https://en.wikipedia.org/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>
											<li id="footer-places-disclaimer"><a href="https://en.wikipedia.org/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>
											<li id="footer-places-contact"><a href="https://en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact Wikipedia</a></li>
											<li id="footer-places-developers"><a href="https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute">Developers</a></li>
											<li id="footer-places-mobileview"><a href="https://en.m.wikipedia.org/w/index.php?title=Stochastic_gradient_descent&mobileaction=toggle_view_mobile" class="noprint stopMobileRedirectToggle">Mobile view</a></li>
									</ul>
										<ul id="footer-icons" class="noprint">
											<li id="footer-copyrightico">
							<a href="https://wikimediafoundation.org/"><img src="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/wikimedia-button.png" srcset="/static/images/wikimedia-button-1.5x.png 1.5x, /static/images/wikimedia-button-2x.png 2x" width="88" height="31" alt="Wikimedia Foundation"></a>						</li>
											<li id="footer-poweredbyico">
							<a href="https://www.mediawiki.org/"><img src="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" srcset="https://en.wikipedia.org/static/1.26wmf21/resources/assets/poweredby_mediawiki_132x47.png 1.5x, https://en.wikipedia.org/static/1.26wmf21/resources/assets/poweredby_mediawiki_176x62.png 2x" width="88" height="31"></a>						</li>
									</ul>
						<div style="clear:both"></div>
		</div>
		<script>window.RLQ = window.RLQ || []; window.RLQ.push( function () {
mw.loader.state({"ext.globalCssJs.site":"ready","ext.globalCssJs.user":"ready","user":"ready","user.groups":"ready"});
} );</script>
<link rel="stylesheet" href="./Stochastic gradient descent - Wikipedia, the free encyclopedia_files/load(5).php">
<script>window.RLQ = window.RLQ || []; window.RLQ.push( function () {
mw.loader.load(["ext.cite.a11y","mediawiki.toc","mediawiki.action.view.postEdit","site","mediawiki.user","mediawiki.hidpi","mediawiki.page.ready","mediawiki.searchSuggest","ext.cirrusSearch.loggingSchema","mmv.bootstrap.autostart","ext.eventLogging.subscriber","ext.wikimediaEvents","ext.wikimediaEvents.statsd","ext.wikimediaEvents.geoFeatures","ext.navigationTiming","ext.gadget.teahouse","ext.gadget.ReferenceTooltips","ext.gadget.DRN-wizard","ext.gadget.charinsert","ext.gadget.refToolbar","ext.gadget.switcher","ext.gadget.featured-articles-links","ext.visualEditor.targetLoader","schema.UniversalLanguageSelector","ext.uls.eventlogger","ext.uls.interlanguage"]);
} );</script><script>window.RLQ = window.RLQ || []; window.RLQ.push( function () {
mw.config.set({"wgBackendResponseTime":65,"wgHostname":"mw1239"});
} );</script>
	

<div class="suggestions" style="display: none; font-size: 13px;"><div class="suggestions-results"></div><div class="suggestions-special"></div></div></body></html>